# FineGym: A Hierarchical Video Dataset for Fine-grained Action Understanding

### 1. 핵심 주장과 주요 기여

FineGym 논문은 기존의 **조잡한 수준의 행동 인식(coarse-grained action recognition) 중심의 문제점**을 지적하고, 이를 해결하기 위한 고품질 데이터셋을 제시합니다. 핵심 주장은 다음과 같습니다.[1]

**문제 인식:** 현대의 행동 인식 모델들은 ImageNet이나 Kinetics와 같은 공개 벤치마크에서는 우수한 성능을 보이지만, 스포츠 분석과 같은 실제 응용 분야에서는 미흡합니다. 특히 활동을 세부 단계로 분해하고 미묘하게 다른 행동들을 구분해야 하는 작업에서 성능이 부족합니다.[1]

**주요 기여:** 두 가지 차원의 기여를 제시합니다. 첫째, **계층적으로 구조화된 주석**을 제공하는 FineGym 데이터셋을 개발했습니다. 세 가지 의미론적 수준(이벤트, 세트, 요소)과 두 가지 시간적 수준(행동, 부분행동)의 주석을 포함합니다. 둘째, 세분화 행동 인식의 **핵심 과제를 체계적으로 분석**하여 향후 연구 방향을 제시합니다.[1]

---

### 2. 해결하고자 하는 문제와 제안 방법

#### 2.1 문제 정의

조잡한 수준의 행동 인식과 세분화 행동 인식의 본질적 차이는 두 가지입니다.[1]

**시간적 차원:** 연속적인 행동을 시간 축을 따라 더 작은 요소로 분해할 수 있는 능력
**의미론적 차원:** 분류 체계의 다음 수준에서 미묘한 차이가 나는 부분 클래스들을 구분할 수 있는 능력

기존 데이터셋(UCF101, Kinetics, ActivityNet)은 배경 맥락(예: 하키 vs 체조)이 판별의 주요 신호가 되는 조잡한 분류에 집중하여, 종목 내 세부 동작 분석에 부족합니다.[1]

#### 2.2 FineGym 데이터셋 구조

FineGym은 체조 종목을 기반으로 구성되며, 고도로 구조화된 주석을 제공합니다.[1]

**의미론적 계층 구조:**
- **이벤트(Event):** 가장 조잡한 수준 - 철봉, 평균대, 마루운동, 도마 등 4개 여성 종목과 6개 남성 종목 총 10개
- **세트(Set):** 중간 수준 - 총 15개의 세트. 예를 들어 평균대의 "하강(dismounts)"
- **요소(Element):** 가장 세분화된 수준 - 총 530개의 요소 클래스. 예: "double salto backward tucked"

**시간적 계층 구조:**
- **행동(Action):** 완전한 체조 루틴 전체의 시작과 끝점
- **부분행동(Sub-action):** 루틴 내에서 각 요소 카테고리에 속하는 동작들의 경계

**핵심 특징:** 신뢰도 점수(Difficulty Value, DV)를 포함한 의사결정 트리를 통해 요소 레벨 주석을 수집합니다.[1]

#### 2.3 데이터셋 통계

Table 1에 따르면, FineGym v1.0의 규모는 다음과 같습니다.[1]

| 항목 | 수치 |
|------|------|
| 총 행동 인스턴스 | 4,883개 |
| 총 부분행동 인스턴스 | 32,697개 |
| 요소 카테고리 (정의됨) | 530개 |
| 요소 카테고리 (실제 인스턴스 있음) | 354개 |
| 비디오 레코드 | 303개 |
| 총 비디오 시간 | ~708시간 |

각 이벤트별로 도마(VT)는 짧은 평균 8초의 동작으로 집중된 움직임을 포함하며, 나머지 종목들은 평균 55초로 더 긴 기간의 동작을 포함합니다.[1]

#### 2.4 품질 관리 메커니즘

고품질 주석을 보장하기 위해 여러 메커니즘을 적용합니다:[1]

1. **데이터 수집:** 국제 체조 연맹(FIG)의 공식 경쟁 기록만 사용
2. **주석자 훈련:** 도메인 전문 지식으로 훈련된 전문 팀 고용
3. **의사결정 트리:** 속성 기반 질의(예: "회전이 있는가?")를 통한 계층적 요소 선택
4. **교차 검증:** 주석자들 간 일관성 확보

***

### 3. 모델 구조 및 실험

#### 3.1 평가 방법론

논문은 세 가지 거리에서 세분화 행동을 평가합니다:[1]

- **모든 이벤트에서의 요소 인식** (Gym288 불균형, Gym99 균형)
- **단일 이벤트 내 요소 인식** (도마[VT], 마루운동[FX])
- **단일 세트 내 요소 인식** (마루운동-도약[FX-G1], 철봉-원[UB-G1])

#### 3.2 평가된 모델 아키텍처

다양한 행동 인식 방법들을 평가합니다:[1]

**2D-CNN 기반 방법:**
- **TSN (Temporal Segment Network):** 3개 세그먼트에서 각각 1개 프레임 샘플링, 평균 풀링으로 시간 집계
- **TRN (Temporal Relational Networks):** 시간적 추론 모듈 포함
- **TSM (Temporal Shift Module):** 시간적 시프팅 모듈 포함

**3D-CNN 기반 방법:**
- **I3D (Inflated 3D ConvNet):** 공간-시간 의미론을 공동으로 학습
- **Non-local Networks:** 장거리 종속성 모델링

**스켈레톤 기반:**
- **ST-GCN (Spatial-Temporal Graph Convolutional Networks):** 인체 키포인트 활용

#### 3.3 성능 분석

**Table 3의 핵심 결과:**

마루운동 요소 인식에서 양방향 입력(RGB + 광학흐름)을 사용한 결과:[1]
- **TRN:** 74.4% mAP, 81.9% Top-1 (FX-G1 세트)
- **TSM:** 72.9% mAP, 79.4% Top-1 (FX-G1 세트)
- **I3D:** 33.3% mAP, 38.9% Top-1 (동일 조건)

이는 모션 특성 캡처의 중요성을 강조합니다.

***

### 4. 성능 향상 및 주요 발견사항

#### 4.1 프레임 샘플링의 필요성

**Figure 5와 Table 5 분석:**[1]

조잡한 수준 인식에서는 3개 프레임(전체의 5%)만으로도 충분하지만, 세분화 인식에서는:[1]

| 프레임 수 | Gym99 정확도 |
|----------|-------------|
| 1 | 35.46% |
| 3 | 61.4% |
| 5 | 70.8% |
| 7 | 74.4% |
| 12 | 78.82% |

12개 프레임(전체의 30%)이 포화 수준의 성능을 달성합니다. 이는 **모든 프레임이 중요**함을 시사합니다.[1]

#### 4.2 모션 정보의 역할

**광학흐름의 중요성:**[1]

- 이벤트 수준: RGB가 더 중요 (배경 맥락 기여)
- 세트 수준: 모션과 RGB가 유사한 기여
- 요소 수준: **모션이 훨씬 중요** (배경 의존성 감소)

**시간적 동역학의 필수성:**

TRN에서 테스트 시 프레임을 섞을 경우 성능 급격히 감소 (Figure 6b), 시간적 동역학이 **필수적**임을 증명합니다.[1]

#### 4.3 사전 학습의 역할

**예상 밖의 발견:**[1]

Kinetics 사전학습 I3D: mAP 36.1% (FX 이벤트)
ImageNet 사전학습 I3D: mAP 33.4%

조잡한 수준 작업용 데이터셋(Kinetics)의 사전학습이 **항상 도움이 되지는 않습니다**. 이는 조잡한-세분화 간 시간적 패턴의 큰 간격 때문입니다.[1]

#### 4.4 스켈레톤 기반 방법의 한계

ST-GCN의 성능이 부족한 이유 (Figure 5):[1]

- 강렬한 움직임(살토 등) 중 인체 탐지 및 포즈 추정 실패
- 체조의 다양한 신체 자세가 포즈 추정을 어렵게 함
- 중간 표현 기반 방법들이 체조 환경에서 도전 과제에 직면

#### 4.5 시간적 행동 위치화

**Table 4 결과:**[1]

| tIoU 임계값 | 행동 mAP | 부분행동 mAP |
|-----------|---------|------------|
| 0.50 | 60.0 | 22.2 |
| 0.90 | 35.0 | 0.6 |

부분행동 위치화가 **훨씬 더 어려운 작업**임을 보여주며, 이는 세분화 경계 정의의 복잡성 때문입니다.[1]

***

### 5. 모델의 일반화 성능과 한계

#### 5.1 일반화 성능 향상의 가능성

논문의 분석에서 도출된 **일반화 향상을 위한 시사점:**

**1. 고주파 시간 정보의 필요성:**
세분화 인식에서는 조밀한 프레임 샘플링이 필수적입니다. 최근의 멀티-모달 비디오 언어 모델(Vid-LLMs)도 이를 인식하여 SlowFocus와 같은 메커니즘을 통해 고주파 지역 세부사항과 저주파 전역 맥락을 함께 유지합니다.[2][3]

**2. 미세 입자도 비디오-텍스트 정렬:**
2024년 최신 연구들은 비디오-텍스트 쌍 정렬의 중요성을 강조합니다. 스토리보드 기반 정렬 방법은 원자적 행동 수준의 의미론을 활용하여 세분화 인식 성능을 개선합니다.[3]

**3. 지식 그래프의 활용:**
세분화 의미론적 연결(행동과 신체 움직임 간)을 활용한 지식 그래프 기반 접근이 일반화 능력을 향상시킵니다.[4]

#### 5.2 현존하는 한계

논문에서 명시적으로 지적하는 한계:[1]

**1. 강렬한 모션 처리:**
살토(1초 이내에 완료)와 같은 빠른 움직임에서 현존 방법들의 성능이 떨어집니다. 프레임 손실이나 모션 블러로 인해 정보 손실 발생.

**2. 미묘한 공간적 의미론:**
신체 부위 위치(다리 구부러짐 vs 펼침), 인체-객체 관계 등 미세한 차이를 구분하기 어렵습니다.

**3. 복잡한 시간적 동역학:**
회전 방향, 회전 횟수와 같은 속성을 정확히 추론하기 어렵습니다.

**4. 포즈 추정의 어려움:**
스켈레톤 기반 방법들은 체조의 극단적 자세에서 실패합니다.

**5. 장거리 종속성 모델링:**
행동 분류 자체보다 경계 정의가 더 어려운 과제입니다 (부분행동 위치화의 낮은 성능).

#### 5.3 도메인 간 전이 학습의 한계

**조잡-세분화 간 전이의 역설:** Kinetics 사전학습이 오히려 FineGym 성능을 해칠 수 있다는 발견은 다음을 시사합니다:[1]

- 도메인 적응 기술의 필요성
- 조잡 단계의 지식이 미세 단계의 학습을 간섭할 수 있음
- 세분화 특화 사전학습 데이터셋의 필요성

***

### 6. 관련 최신 연구와 향후 고려사항

#### 6.1 최신 연구 동향(2024년 기준)

**1. 다중 입자도 프레임워크의 대두:**
FineSports 데이터셋(2024)은 다중 인물 스포츠 환경에서 세분화 행동 분석을 확장했으며, 프롬프트 기반 공간-시간 행동 위치화(PoSTAL) 방법을 제시했습니다. 이는 **세분화 인식이 스포츠 분석 분야로 확대**되고 있음을 보여줍니다.[5]

**2. 비전-언어 모델의 통합:**
ActionCLIP 및 지식 그래프 기반 방법들은 **다중 모달 표현 학습**을 통해 일반화 성능을 향상시킵니다. 특히 미세 의미론적 연결을 활용하는 접근이 강조됩니다.[2][4]

**3. 시간 세분화의 강화:**
SlowFocus 메커니즘(2024)은 비디오 언어 모델에서 고주파 시간 정보와 저주파 전역 맥락의 균형을 유지합니다. 이는 FineGym의 고주파 샘플링 필요성 발견을 직접 반영합니다.[3]

**4. 자체 지도 학습과 도메인 적응:**
Self-Supervised Temporal Domain Adaptation (SSTDA)는 레이블 없는 비디오를 활용한 시간적 동역학 학습을 가능케 합니다. 이는 조잡-세분화 간 도메인 갭을 극복하는 방안입니다.[6]

#### 6.2 앞으로의 연구 시 고려할 점

**1. 고주파 시간 특성 모델링:**
- 더 정교한 광학흐름 추출 방법
- 변환기(Transformer) 기반 시간 모델링의 확장
- 적응형 프레임 샘플링 전략

**2. 지식 통합:**
- 도메인 전문 지식(의사결정 트리)의 명시적 활용
- 물리적 제약(신체 운동학)의 모델 내 통합
- 속성 기반 예측과 분류의 결합

**3. 전이 학습 재고:**
- 세분화 특화 사전학습 코퍼스 구축
- 적응형 미세 조정 전략
- 조잡-세분화 간 지식 교환의 양방향 설계

**4. 다중 모달 표현:**
- 비디오-텍스트 정렬의 원자적 수준 적용
- 의미론적 임베딩 공간에서의 거리 학습
- 지식 그래프와의 통합

**5. 데이터셋 확장:**
- 다양한 스포츠 종목으로 확대
- 실시간 응용을 위한 저해상도 버전
- 자동 주석 생성 기법의 개발

**6. 평가 지표 개선:**
- 부분 정확도를 포함한 다차원 평가
- 오류 분석 시각화의 체계화
- 실제 응용 시나리오 기반 벤치마킹

#### 6.3 응용 분야의 확대

논문이 언급한 잠재적 응용 분야들은 실제로 구현되고 있습니다:[1]

- **자동 채점:** 난이도 점수 기반 품질 평가
- **행동 생성:** 의도된 움직임의 비디오 합성
- **다중 속성 예측:** 의사결정 트리의 속성 정보 활용
- **모델 해석성:** 트리 경로를 통한 의사결정 추적

***

### 결론

FineGym은 **조잡한 수준의 행동 인식과 세분화 행동 인식 사이의 근본적 차이**를 실증적으로 보여주며, 이를 해결하기 위한 고품질 데이터셋과 체계적 분석을 제공합니다. 특히 시간적 밀도, 모션 정보의 중요성, 도메인 특화 사전학습의 필요성 등의 발견은 **향후 세분화 행동 인식 연구의 방향을 정립**했습니다.[1]

최근 2024년의 연구 동향은 FineGym의 발견을 기반으로 **다중 모달 표현**, **지식 통합**, **적응형 시간 모델링**으로 발전하고 있습니다. 이는 세분화 행동 인식이 이론적 문제를 넘어 실제 스포츠 분석, 체능 평가, 로봇 학습 등 다양한 분야로 확대되고 있음을 의미합니다.[4][5][6][2][3]

***

### 참고문헌 및 인용

 Shao et al., "FineGym: A Hierarchical Video Dataset for Fine-grained Action Understanding", CVPR 2020[1]
 Luo et al., "ActionCLIP: A New Paradigm for Video Action Recognition", 2021[2]
 Liu et al., "Storyboard guided Alignment for Fine-grained Video Action Recognition", 2024[3]
 Zhang et al., "Fine-grained Knowledge Graph-driven Video-Language Learning for Action Recognition", 2024[4]
 Xu et al., "FineSports: A Multi-person Hierarchical Sports Video Dataset for Fine-grained Action Understanding", CVPR 2024[5]
 "Self-Supervised Temporal Domain Adaptation", SSTDA 논문[6]

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/910d31ec-c3e0-41f9-9cba-5ded2ee3fe10/2004.06704v1.pdf)
[2](https://arxiv.org/pdf/2109.08472.pdf)
[3](http://arxiv.org/pdf/2410.14238.pdf)
[4](https://downloads.hindawi.com/journals/ijis/2024/1052344.pdf)
[5](http://arxiv.org/pdf/2407.14146.pdf)
[6](http://arxiv.org/pdf/1811.01549.pdf)
[7](https://arxiv.org/pdf/2308.03063.pdf)
[8](https://www.mdpi.com/1424-8220/21/24/8309/pdf)
[9](https://arxiv.org/html/2411.15106)
[10](https://proceedings.neurips.cc/paper_files/paper/2024/file/94ef721705ea95d6981632be62bb66e2-Paper-Conference.pdf)
[11](https://www.youtube.com/watch?v=ffpeRwLZFXI)
[12](https://arrow.tudublin.ie/cgi/viewcontent.cgi?article=1003&context=impvseone)
[13](https://arxiv.org/abs/2410.14238)
[14](https://github.com/nus-cvml/awesome-temporal-action-segmentation)
[15](https://onlinelibrary.wiley.com/doi/10.1155/2024/4187991)
[16](https://openaccess.thecvf.com/content/CVPR2024/html/Xu_FineSports_A_Multi-person_Hierarchical_Sports_Video_Dataset_for_Fine-grained_Action_CVPR_2024_paper.html)
[17](https://arxiv.org/pdf/2210.10352.pdf)
[18](https://www.nature.com/articles/s41598-024-78414-2)
[19](https://kixlab.github.io/website-files/2024/cvpr2024-finegrained-workshop.pdf)
