# CNN-Generated Images are Surprisingly Easy to Spot... for Now

### 1. 핵심 주장 및 기여

이 논문의 가장 중요한 발견은 **일반화 가능한 CNN 생성 이미지 검출기가 가능하다**는 것이다. 저자들은 다음의 핵심 주장을 제시한다:[1]

첫째, 오늘날의 CNN 기반 이미지 생성 모델(ProGAN, StyleGAN, BigGAN, CycleGAN 등)이 생성하는 이미지들이 **공통적인 인공적 결함(artifacts)을 포함**하고 있다는 것이다. 이러한 결함들은 특정 생성 모델에 대해 학습된 분류기가 다른 아키텍처와 데이터셋으로 학습된 이미지들도 효과적으로 탐지할 수 있게 한다.[1]

둘째, 저자들은 **ProGAN만으로 학습한 단순한 이진 분류기(binary classifier)**가 11개의 서로 다른 CNN 기반 생성 모델로부터 생성된 이미지들을 놀랍도록 잘 탐지할 수 있음을 보여준다. 이는 이전 연구들이 보고한 일반화 성능의 한계를 극복하는 결과이다.[1]

셋째, 저자들은 ForenSynths 데이터셋과 평가 메트릭을 제안하여 **CNN 생성 이미지 탐지에 대한 벤치마크를 구축**했다.[1]

주요 기여는 다음 세 가지로 정리된다: (1) CNN 생성 이미지 탐지에서 놀라운 일반화 능력 입증, (2) 새로운 데이터셋 및 평가 메트릭 제안, (3) 크로스 모델 일반화에 기여하는 요인에 대한 실험적 분석.[1]

---

### 2. 문제 정의, 방법론, 모델 구조 및 성능

#### 2.1 문제 정의

이 연구가 해결하고자 하는 핵심 문제는 다음과 같다:

**"CNN으로 생성된 모든 이미지를 탐지할 수 있는 범용 검출기를 만들 수 있을까?"**[1]

기존 접근 방식의 문제점은 다음과 같다. 특정 생성 기법으로 학습된 탐지기는 곧 구식이 되며, 새로운 데이터셋이나 생성 방식에 대해 일반화되지 못한다. 또한 이전 연구들은 한 GAN 아키텍처에서 학습한 분류기가 다른 GAN에 대해 매우 낮은 성능을 보인다고 보고했다.[1]

#### 2.2 방법론 및 모델 구조

**기본 아키텍처:**

저자들은 **ResNet-50**을 ImageNet 사전학습 가중치로 사용하여 이진 분류 문제로 설정했다. 모델은 실제 이미지인지 가짜 이미지인지를 분류한다:[1]

$$
y = \text{Classifier}(x) \in \{0 \text{ (real)}, 1 \text{ (fake)}\}
$$

여기서 $$x$$는 224×224 크기의 입력 이미지이다.

**핵심 방법론: 데이터 증강(Data Augmentation)**

논문의 가장 중요한 발견은 **적절한 데이터 증강이 일반화 성능을 획기적으로 향상**시킨다는 것이다. 저자들은 다음의 증강 기법을 제안했다:[1]

1. **기본 증강**: 좌우 반전(left-right flip) 및 224×224 무작위 크롭
2. **가우시안 블러**: 50% 확률로 σ ∈ Uniform(0, 3) 적용
3. **JPEG 압축**: 50% 확률로 품질 Q ∈ Uniform(30, 31, ..., 100)
4. **복합 증강**: BlurJPEG 0.5 (블러와 JPEG, 각각 50% 확률), BlurJPEG 0.1 (각각 10% 확률)

증강의 수학적 표현:

$$
\tilde{x} = \text{Augment}(x; p_{\text{blur}}, p_{\text{jpeg}})
$$

여기서 $$p_{\text{blur}}$$와 $$p_{\text{jpeg}}$$는 각각의 증강이 적용될 확률이다.

**학습 설정:**

- 옵티마이저: Adam ($$\beta_1 = 0.9$$, $$\beta_2 = 0.999$$)
- 배치 크기: 64
- 초기 학습률: $$10^{-4}$$
- 조기 종료: 5 에포크 동안 검증 정확도가 0.1 이상 증가하지 않으면 학습률을 10배 감소
- 평가 메트릭: **Average Precision (AP)** - 임계값 비의존적 순위 기반 점수[1]

#### 2.3 성능 향상 결과

**증강의 효과:**

| 증강 방법 | ProGAN | StyleGAN | BigGAN | CycleGAN | 평균 AP |
|----------|--------|----------|--------|----------|---------|
| 증강 없음 | 100.0 | 96.3 | 72.2 | 84.0 | 90.1 |
| 블러만 | 100.0 | 99.0 | 82.5 | 90.1 | 84.4 |
| JPEG만 | 100.0 | 99.0 | 87.8 | 93.2 | 93.0 |
| BlurJPEG 0.5 | 100.0 | 98.5 | 88.2 | 96.8 | 90.8 |

특히 **BigGAN에서 72.2% → 88.2%로 증가**하는 등 상당한 성능 향상을 보였다.[1]

**데이터 다양성의 영향:**

학습 데이터에 포함된 LSUN 클래스 수를 증가시킬 때:

$$
\text{Performance} \propto \log(\text{Number of Classes})
$$

- 2 클래스: mAP 81.3
- 4 클래스: mAP 85.4
- 8 클래스: mAP 87.9
- 16 클래스: mAP 91.4
- 20 클래스: mAP 90.8

**포화점 발생**: 16개 클래스 이후 개선 효과가 감소하기 시작한다.[1]

**크로스 모델 일반화 성능:**

ProGAN으로 학습한 모델이 다른 생성 모델에 대해 보인 성능:

| 생성 모델 | AP |
|---------|-----|
| StyleGAN | 98.5 |
| BigGAN | 88.2 |
| CycleGAN | 96.8 |
| StarGAN | 95.4 |
| GauGAN | 98.1 |
| CRN | 98.9 |
| IMLE | 99.5 |
| SITD | 92.7 |
| SAN | 63.9 |
| DeepFake | 66.3 |

**StyleGAN2 (새로운 모델)에 대한 성능:**

놀랍게도, 원본 논문 이후 발표된 StyleGAN2에 대해 99.1 AP를 달성했다. 이는 **새로운 생성 모델에 대한 우수한 확장성**을 보여준다.[1]

#### 2.4 견고성 평가 (Robustness)

**가우시안 블러에 대한 견고성:**

$$
x_{\text{blur}} = \text{GaussianBlur}(x; \sigma) \text{ where } \sigma \in 
$$

- 증강 없음: σ=4일 때 심각한 성능 저하 (예: ProGAN 100% → ~20%)
- BlurJPEG 0.5 증강: σ=4일 때에도 대부분 높은 성능 유지[1]

**JPEG 압축에 대한 견고성:**

$$
x_{\text{jpeg}} = \text{JPEGCompress}(x; Q) \text{ where } Q \in 
$$

- 증강 없음: Q=30일 때 급격한 성능 저하
- BlurJPEG 0.5 증강: Q=30에서도 80% 이상 AP 유지[1]

---

### 3. 모델의 일반화 성능 향상 가능성 분석

#### 3.1 일반화를 가능하게 하는 요인

**CNN 아티팩트의 공통성:**

저자들은 주파수 영역 분석을 통해 다양한 CNN 생성 이미지들이 공통적인 주기적 패턴을 보인다는 것을 입증했다. 고주파 필터링 후 푸리에 변환을 수행한 시각화에서:[1]

$$
\mathcal{F}(\text{HighPass}(x)) = \mathcal{F}(x - \text{MedianBlur}(x, k))
$$

이는 **Aliasing 아티팩트**로 알려진 현상으로, CNN의 스트라이드 컨볼루션과 업샘플링 구조에서 발생한다.[1]

**데이터 다양성의 역할:**

학습 데이터의 의미론적 다양성이 매우 중요하다. 20개의 LSUN 클래스(비행기, 자동차, 고양이, 말 등)로부터의 이미지를 포함하면:

$$
\text{AP}(\text{test model}) = f(\text{Diversity}, \text{Augmentation})
$$

단순히 같은 클래스의 더 많은 이미지보다 **다양한 의미론적 내용의 데이터가 더 효과적**이다.[1]

#### 3.2 제한적 일반화 사례

**세 가지 예외 사항:**

1. **Super-Resolution (SAN)**: 고주파 성분만 진짜/가짜를 구분하므로, 블러 증강이 성능을 해친다 (93.6% → 53.7%).[1]

2. **DeepFake**: 광범위한 후처리(Poisson 블렌딩, MPEG 압축)를 거치므로 CNN 아티팩트가 손상된다. 따라서 BlurJPEG 0.1이 BlurJPEG 0.5보다 나음 (89.0% vs 63.9%).[1]

3. **Visual Quality와의 약한 상관성**: BigGAN과 StarGAN 외에는 모델의 신뢰도(fakeness score)와 시각적 품질 간의 상관성이 거의 없다. 이는 모델이 **낮은 수준의 CNN 아티팩트를 학습**하고 있음을 시사한다.[1]

#### 3.3 일반화 성능 향상의 한계

**In-the-wild 테스트에서의 성능 저하:**

whichfaceisreal.com에서 수집한 1024×1024 StyleGAN 이미지로 테스트했을 때:[1]

- 중앙 크롭 (256→224): 93.2 AP
- 리사이즈 (256→224): 82.6 AP

**상당한 후처리가 적용된 경우 성능이 급격히 저하**되므로, 실제 배포 환경에서의 견고성 개선이 필요하다.

**모델 신뢰도(Confidence)의 한계:**

악의적인 사용자는 다음과 같은 공격 방식을 사용할 수 있다:[1]

$$
\text{Attack: Select } x^* = \arg\min_{x \in \mathcal{G}} P(\text{fake}|x)
$$

즉, 생성 이미지들 중에서 가장 진짜처럼 보이는 이미지만 선택하여 배포하면 되므로, 단일 이미지 탐지의 신뢰도에는 한계가 있다.

***

### 4. 한계 및 미래 연구 방향

#### 4.1 기술적 한계

**1. 얕은(Shallow) 조작 기법에 대한 실패:**

Photoshop과 같은 전통적 이미지 편집 도구로 생성된 이미지에는 작동하지 않는다. 논문에서 Liquify 데이터셋에 대해 50% 정확도(확률 수준)을 보였다.[1]

**2. 향후 GAN 아키텍처에 대한 예측 불가:**

만약 GAN이 Nash 평형에 도달하여 완벽하게 수렴하면, 모든 현재의 탐지 방법이 무효화될 수 있다:[1]

```math
\text{If } \exists \pi_G^*, \pi_D^* : \text{GAN loss} = \text{equilibrium} \Rightarrow \text{Detection impossible}
```

#### 4.2 실무적 도전 과제

**1. 연쇄 후처리로 인한 성능 저하:**

소셜 미디어(Facebook, Twitter, YouTube) 플랫폼의 압축과 재샘플링 체인을 극복해야 한다.[1]

**2. 거짓 양성(False Positive) 문제:**

탐지기는 항상 실제 이미지를 거짓으로 탐지할 위험이 있으며, 이의 최소화는 중요한 실무 과제이다.[1]

#### 4.3 향후 연구 시 고려할 점

**1. 다층적 방어 전략의 필요성:**

단순히 기술적 탐지만으로는 부족하며, **사회적, 법적 대응책도 포함**되어야 한다.[1]

**2. 적응적 생성 모델 개발:**

새로운 생성 모델들이 탐지 기술을 회피할 수 있도록 설계될 수 있으므로, **대치(adversarial) 관점**의 연구 필요.[1]

**3. 초현실적 이미지 생성의 가능성:**

현재의 아티팩트들이 제거되면, **완전히 다른 탐지 방식**을 고안해야 한다.[1]

**4. 도메인 적응 강화:**

특정 도메인(얼굴, 풍경, 의료 이미지 등)에 특화된 탐지 모델 개발도 중요하다.

***

## 결론

이 논문은 **CNN 생성 이미지 탐지에서 일반화 가능성이 존재한다**는 중요한 발견을 제시한다. 특히 **적절한 데이터 증강과 충분한 데이터 다양성**을 통해 단일 모델에서 학습한 분류기가 11개의 서로 다른 아키텍처에 모두 효과적으로 적용될 수 있음을 보여준다. 

그러나 동시에 **기술의 본질적 한계**(GAN의 이론적 발전, 얕은 조작 기법, 현실의 복잡한 후처리)를 명확히 제시함으로써, 이 분야의 **군비 경쟁(arms race) 특성**을 강조한다. 앞으로의 연구는 기술 개발과 함께 정책, 사회적 대응을 포함한 **통합적 접근**이 필요함을 시사한다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/17a8924c-f015-4ae3-939b-0f16548a414f/1912.11035v2.pdf)
