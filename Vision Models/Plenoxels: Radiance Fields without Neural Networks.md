# Plenoxels: Radiance Fields without Neural Networks

### 1. 핵심 주장과 주요 기여

**Plenoxels**는 신경망을 완전히 배제하면서도 **Neural Radiance Fields (NeRF)** 수준의 포토리얼리스틱 화면 합성을 달성하는 혁신적인 방법입니다. 이 논문의 핵심 주장은 **"포토리얼리스틱 볼륨 재구성의 핵심은 신경망이 아니라 미분 가능한 볼륨 렌더러"**라는 것입니다.[1]

주요 기여는:

- **속도 혁신**: 훈련 시간을 **100배 이상 단축** (약 1일 → 11분)[1]
- **품질 유지**: NeRF와 동등한 시각 품질 달성
- **명시적 표현**: 학습 가능한 신경망 없이 직접 최적화 가능한 명시적 3D 표현
- **실용성 향상**: 단일 Titan RTX GPU에서 대부분의 장면을 30분 이내에 최적화

이러한 성과는 **역 문제(inverse problem)의 고전적 도구들** - 데이터 표현, 포워드 모델, 정규화 함수, 최적화기 - 이 얼마나 효과적인지를 입증합니다.[1]

---

### 2. 문제 정의, 제안 방법, 모델 구조

#### **문제 정의**
NeRF가 달성한 포토리얼리스틱 품질은 인상적이지만, 심각한 계산 병목 현상을 야기합니다:[1]
- 훈련: GPU당 1일 이상 소요
- 렌더링: 프레임당 약 30초 필요
- 이는 현실적인 3D 재구성 응용을 크게 제약

#### **제안 방법 및 수식**

**Plenoxel의 핵심 표현**:[1]
- 장면을 **희소(sparse) 3D 복셀(voxel) 그리드**로 표현
- 각 복셀은 **구면 조화 계수(spherical harmonic coefficients)**를 저장
- 구면 조화의 차수는 2차로 선택 (각 컬러 채널당 9개 계수)

**체적 렌더링 공식** (Max의 공식 사용):[1]

$$T_i = \exp(-\sigma_i \delta_i)$$

$$C(r) = \sum_{i=1}^{N} (T_i - T_{i+1}) C_i$$

여기서 $T_i$는 누적 투과율(accumulated transmittance), $\sigma_i$는 불투명도(opacity), $\delta_i$는 샘플 거리, $C_i$는 색상입니다.

**보간(Interpolation)**:[1]

$$\text{삼선형 보간(Trilinear Interpolation)}$$

- 가장 가까운 8개 복셀의 불투명도와 조화 계수를 보간
- 연속 함수 근사와 세부 해상도 향상의 **이중 이점** 제공

**최적화 목적 함수**:[1]

$$L = L_{\text{recon}} + \lambda_{TV} L_{TV}$$

$$L_{\text{recon}} = \frac{1}{|R|} \sum_{r \in R} \|C(r) - \hat{C}(r)\|_2^2$$

$$L_{TV} = \frac{1}{|V|} \sum_{v \in V} \sum_{d \in [D]} \left(\Delta_x^2(v,d) + \Delta_y^2(v,d) + \Delta_z^2(v,d)\right)$$

여기서:
- $L_{\text{recon}}$는 평균 제곱 오차(MSE) 재구성 손실
- $L_{TV}$는 전변(total variation) 정규화
- $\lambda_{TV}$는 각 장면 유형별로 고정된 가중치

**정규화 항**:[1]
- **희소성 손실** (실제 장면용):

$$L_s = \lambda_s \sum_{i,k} \log(1 + 20(r_i(t_k))^2)$$

- **베타 분포 정규화** (360° 장면용):

$$L_\beta = \lambda_\beta \sum_r (\log(T_{FG}(r)) + \log(1 - T_{FG}(r)))$$

#### **모델 구조**

1. **희소 복셀 그리드 구조**:[1]
   - 포인터 격자 + 데이터 테이블 구조
   - NULL 셀은 0값으로 처리하여 메모리 효율성 달성

2. **단계별 최적화 (Coarse-to-Fine)**:[1]
   - 낮은 해상도(예: 256³)에서 시작
   - 39,400 스텝 후 불필요한 복셀 제거
   - 512³로 업샘플링
   - 최종 해상도(예: 512³)까지 반복
   - 각 업샘플링 후 삼선형 보간으로 값 초기화

3. **경계 없는 장면 확장**:[1]
   - **정방향(Forward-facing) 장면**: 정규화된 장치 좌표(NDC) 사용
   - **360° 장면**: 다중 구형 이미지(Multi-Sphere Image, MSI) 배경 모델
     - 64개 구면을 역 반지름에서 선형으로 배치 (1 ~ ∞)
     - 각 배경 구면도 복셀 그리드 + 삼선형 보간 구조

4. **최적화 기법**:[1]
   - **옵티마이저**: RMSProp 사용 (2차 최적화의 복잡도 제거)
   - **배치 크기**: 5,000개 광선(ray)
   - **학습률 스케줄**:
     - $\sigma$(불투명도): 지연 지수 감소 (30에서 0.05로, 250,000 스텝)
     - SH(구면 조화): 순수 지수 감소 (0.01에서 $5 \times 10^{-6}$로)

***

### 3. 성능 향상 및 한계

#### **성능 지표**

| 장면 유형 | PSNR ↑ | SSIM ↑ | LPIPS ↓ | 훈련 시간 |
|----------|--------|--------|---------|----------|
| 합성 장면 (synthetic) | 31.71 | 0.958 | 0.049 | **11분** |
| NeRF (기준) | 31.85 | 0.954 | 0.072 | 1.45일 |
| 정방향 실제 장면 | 26.29 | 0.839 | 0.210 | **24분** |
| JAXNeRF (기준) | 26.71 | 0.820 | 0.235 | 1.62일 |
| 360° 실제 장면 | 20.40 | 0.696 | 0.420 | **27분** |
| NeRF++ (기준) | 20.49 | 0.648 | 0.478 | ~4일 |

**핵심 결과**: Plenoxels는 **거의 동등하거나 우수한 품질**을 유지하면서 **100배 이상의 속도 향상** 달성[1]

#### **삼선형 보간의 중요성**:[1]

| 방법 | PSNR | SSIM | LPIPS |
|------|------|------|-------|
| 삼선형, 256³ | 30.57 | 0.950 | 0.065 |
| 삼선형, 128³ | 28.46 | 0.926 | 0.100 |
| 최근접, 256³ | 27.17 | 0.914 | 0.119 |
| 최근접, 128³ | 23.73 | 0.866 | 0.176 |

**발견**: 삼선형 보간이 **연속성**과 **효과적 해상도** 두 측면에서 핵심 역할[1]

#### **제한 사항**

1. **아티팩트 특성**: 신경망 기반 방법과 다른 형태의 아티팩트 생성[1]
   - 예: 광택 표면에서 다른 종류의 반사 왜곡

2. **하이퍼파라미터 민감성**: TV 가중치($\lambda_{TV}$)의 사전 최적값 불확실[1]
   - 장면별 튜닝으로 성능 향상 가능

3. **데이터 희소성 대응**: 제한된 입력 데이터에서는 강화된 TV 정규화 필요[1]
   - 25개 뷰로 학습할 때 높은 TV 정규화 적용

4. **렌더링 속도**: 최적화되지 않은 렌더링 구현 (15 fps)[1]
   - PlenOctree로 변환하면 실시간 렌더링 가능

---

### 4. 일반화 성능 향상 가능성 (심화 분석)

#### **현재 Plenoxels의 일반화 특성**

Plenoxels는 기본적으로 **장면별 최적화(per-scene optimization)** 방식이기 때문에 **크로스-장면 일반화**에는 원래 설계되지 않았습니다. 그러나 여러 관점에서 일반화 성능 향상이 가능합니다:

**1. 데이터 희소 환경에서의 강점**[1]
- 100개 뷰 → 25개 뷰로 감소 시 TV 정규화 증가로 NeRF 초과 달성
- 이는 강력한 귀납 편향(inductive bias)이 정규화를 통해 구현됨을 시사

**2. 추천 개선 방향 (최신 연구 기반)**

**a) 생성 모델로의 확장 (Generalizable Plenoxels)**[2][3]
- MVSNeRF 방식: 다중 장면 학습으로 크로스-장면 일반화 구현
- 복셀 그리드에 특징 추출기 추가
- 고정된 구면 조화 대신 학습 가능한 특징 필드 사용

**b) 계층적 표현 학습**[3]
- 장면 고유 특성(scene-specific details) 보존
- 공유 가능한 기하 정보(shared geometry) 학습
- 깊이 인식 샘플링(depth-aware sampling)으로 효율성 향상

**c) 메타-러닝 접근**[4][2]
- 소수 뷰(few-shot) 환경에서 빠른 적응
- 기존 크로스-장면 모델과 결합한 하이브리드 접근

#### **최신 유사 연구들의 시사점**

**Gen-NeRF (2023-2025)**: 일반화 가능한 NeRF의 실시간화[3]
- 알고리즘-하드웨어 공동 설계로 실시간 크로스-장면 렌더링 구현
- Plenoxels의 빠른 특성과 결합하면 더욱 혁신적 결과 가능

**DARF (2025)**: 깊이 인식 일반화 NeRF[5]
- 깊이 추정으로 장면의 고유성 보존
- 샘플 50% 감소하며 품질 향상
- Plenoxels에 적용 시 희소 표현의 효율성 극대화 가능

**FreeSplat (2024)**: 일반화 가능한 3D 가우시안 스플래팅[6]
- 픽셀 정렬 3D 가우시안 삼중체
- 긴 수열 입력 처리로 광범위 뷰 보간/외삽 지원
- 명시적 표현에서의 일반화 방식 제시

**TimeNeRF (2024)**: 시간적 일반화[7]
- 소수 뷰 + 다중 시간 스탠프로부터의 학습
- 암시적 콘텐츠 필드 + 시간 의존성
- 제안: Plenoxels에 시간적 복셀 변형 모듈 추가 가능

#### **Plenoxels 일반화 향상을 위한 구체적 전략**

1. **특징 그리드 추가** (Feature Grid + Plenoxels)
   - 각 복셀에 고정 구면 조화 외에 학습 가능한 특징 저장
   - 크로스-장면 인코더 네트워크로 특징 예측
   - 여전히 신경망의 렌더링 쿼리 제거 (Plenoxels의 핵심 이점 유지)

2. **멀티태스크 정규화**
   - 여러 장면의 기하 일관성 제약
   - 시맨틱 특징 정렬 손실
   - 장면 간 변형 필드(deformation field) 학습

3. **계층적 복셀 구조**
   - 조대(coarse) 해상도에서 공유 기하
   - 세분(fine) 해상도에서 장면 고유 세부사항
   - 옥트리 기반 동적 해상도 조정

4. **깊이 선행 정보 통합**[5]
   - 외부 깊이 추정 모델로 초기화
   - 불투명도 최적화 범위 제약
   - 표면 근처 샘플링 집중

***

### 5. 향후 연구에 미치는 영향 및 고려 사항

#### **연구 커뮤니티에 미친 영향**

1. **신경망 없는 표현의 재평가**[1]
   - "신경망이 필수 아닌가?"라는 근본적 질문 제기
   - 고전적 신호 처리와 현대적 최적화 기법의 결합 입증

2. **명시적 vs. 암시적 표현의 균형 모색**[8][2][6]
   - Plenoxels 출시 후 3D 가우시안 스플래팅 등 명시적 방법 활성화
   - 각 장면 특성에 따른 표현 선택의 중요성 부각

3. **응용 분야 확장**
   - RGB-D 매핑 및 추적[9]
   - 동적 장면 렌더링[10]
   - 포즈 추정[8]

#### **향후 연구 시 핵심 고려 사항**

**1. 메모리-품질-속도 트레이드오프**
- 현재: 충분한 VRAM (11GB+)에서 우수성 입증
- 과제: 모바일/경량 디바이스 배포
- 제안: 적응형 복셀 공간 분할, 양자화 기법 연구

**2. 크로스-장면 일반화의 복잡성**
- Plenoxels는 장면별 최적화로 뛰어나지만, 새로운 장면마다 재학습 필요
- 개선 방향: 특징 그리드 + 경량 특징 추출 네트워크 하이브리드
- 주의: 신경망 제거의 원래 장점(해석성, 속도) 유지 필수

**3. 정규화 선택의 장면 의존성**
- TV 정규화 가중치가 장면별로 최적화 필요
- 개선 방향: 자동 정규화 가중치 선택 알고리즘
- 메타-러닝으로 초기 추정값 학습

**4. 렌더링 최적화**[1]
- 현재 15 fps는 실시간 부족
- 기존 순차 렌더링 → CUDA 커널 최적화 필요
- 제안: 계층적 표현과 조기 종료(early termination) 활용

**5. 물리 기반 렌더링(Physically-Based Rendering)으로의 확장**
- 현재: 복사 휘도 필드 중심
- 미래: 표면 속성 분해 (법선, 거칠기, 금속성)
- 보다 복잡한 광학 상호작용 모델링

**6. 동적 및 비강체 장면**[11][12][10]
- 정적 장면만 가정한 한계 극복
- 변형 필드 또는 계층적 변환 추가
- Plenoxels의 속도 이점 유지하며 시공간 일관성 보장

#### **최신 트렌드 기반 제안**

현재 (2025년) 연구 트렌드에 따르면:

- **3D 가우시안 스플래팅과의 하이브리드**: 명시적 점 구름(가우시안)의 학습 가능성 + 복셀의 메모리 효율 결합

- **멀티모달 표현**: 텍스트, 시간, 카메라 파라미터 조건부 생성 모델로 확장

- **실시간 성능 달성**: Gen-NeRF의 알고리즘-하드웨어 공동 설계 패러다임 도입으로 산업 응용 가능성 향상

- **자동 영역 적응**: 새로운 도메인(실내/실외, 주간/야간)에 대한 자동 정규화 선택

***

## 결론

**Plenoxels**는 단순함 속의 우아함을 보여주는 연구로, 신경망이 모든 3D 표현 학습의 필수 요소는 아님을 증명했습니다. 이는 3D 비전 연구를 **"더 복잡한 모델"에서 "더 효율적인 알고리즘"**으로의 패러다임 전환을 촉발했습니다.[1]

향후 Plenoxels의 일반화 성능 향상은 **경량 특징 네트워크 + 강력한 정규화**의 조합과 **메타-러닝 기반 하이퍼파라미터 자동화**를 중심으로 진행될 것으로 예상됩니다. 특히 **크로스-도메인 적응**과 **동적 장면 확장**이 주요 연구 방향이 될 것입니다.

***

### 참고 논문 및 출처

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/ecffb508-640a-476f-a025-8c46499937cd/2112.05131v1.pdf)
[2](http://arxiv.org/pdf/2305.18163.pdf)
[3](https://arxiv.org/html/2402.04632)
[4](https://arxiv.org/abs/2112.05131)
[5](http://arxiv.org/pdf/2212.02280.pdf)
[6](https://arxiv.org/html/2403.10773v1)
[7](http://arxiv.org/pdf/2312.12337.pdf)
[8](http://arxiv.org/pdf/2307.03404.pdf)
[9](https://openaccess.thecvf.com/content/CVPR2022/papers/Fridovich-Keil_Plenoxels_Radiance_Fields_Without_Neural_Networks_CVPR_2022_paper.pdf)
[10](https://arxiv.org/pdf/2103.15595.pdf)
[11](https://proceedings.mlr.press/v202/fu23g/fu23g.pdf)
[12](https://npucvr.github.io/NDVG/)
