# Diff-Retinex: Rethinking Low-light Image Enhancement with A Generative Diffusion Model

## 1. 핵심 주장과 주요 기여

**핵심 주장**

Diff-Retinex는 저조도 영상 향상 문제를 단순한 복원 작업이 아닌 생성 작업으로 재정의합니다. 기존 방법들이 저조도 영상의 손상된 정보를 복원하는 데 머물렀다면, Diff-Retinex는 누락된 장면 내용과 색상 정보를 생성적으로 추론하고 복원할 수 있는 능력을 제공합니다.[1]

**주요 기여**

1. **생성적 관점의 재해석**: 저조도 영상 향상을 조건부 영상 생성 문제로 접근하여 원본 영상의 저품질 정보 향상에 머물지 않고 누락된 내용을 보완하고 색상 편차를 복원하는 생성적 Retinex 프레임워크를 제안[1]

2. **Transformer 기반 분해 네트워크**: Retinex 모델의 분해 문제를 해결하기 위해 새로운 Transformer 분해 네트워크(TDN)를 설계하여 어텐션과 계층적 의존성을 활용해 고해상도 영상에서도 효율적인 분해 성능을 제공[1]

3. **확산 모델의 최초 적용**: Retinex 모델과 확산 모델을 결합한 최초의 연구로서, 조명과 반사도 맵의 다중 경로 조정을 통해 더 나은 성능을 달성[1]

## 2. 해결 문제와 제안 방법

**해결하고자 하는 문제**

저조도 영상에서 가장 까다로운 문제는 **장면 구조의 손실**입니다. 기존 방법들은 노이즈 제거를 통해 손상된 장면을 더 잘 렌더링할 수 있지만, 누락된 장면 내용을 복구할 수는 없었습니다. 예를 들어, 최신 기법인 URetinex도 약하고 누락된 디테일을 복원하지 못하고 오히려 정보 왜곡을 증가시키는 경우가 있습니다.[1]

**제안 방법**

### Retinex 분해 이론

클래식한 Retinex 이론에 따라 영상을 반사도와 조명 맵으로 분해합니다:

$$I = R \cdot L $$[1]

여기서 $$I$$는 입력 영상, $$R$$은 반사도 맵, $$L$$은 조명 맵입니다.

### 최적화 목표

Retinex 분해를 위한 최적화 목적 함수는 다음과 같습니다:

$$\min_{R,L} \tau(R \cdot L) + \alpha\phi(R) + \beta\psi(L) $$[1]

여기서:
- $$\tau(R \cdot L)$$: 재구성 손실
- $$\phi(R)$$: 반사도 일관성 제약
- $$\psi(L)$$: 조명의 부분적 매끄러움 제약

### 손실 함수

**재구성 손실**:

$$L_{rec} = \|R_n \cdot L_n - I_n\|\_1 + \alpha_{rec}\|R_l \cdot L_l - I_l\|\_1 + \xi(L_{crs}) $$ [1]

**반사도 일관성 손실**:

$$L_{rc} = \|R_n - R_l\|_1 $$ [1]

**조명 매끄러움 손실**:

$$L_{smooth} = \|W_l^T \cdot \nabla L_l\| + \|W_n^T \cdot \nabla L_n\| $$ [1]

### 확산 모델 과정

**순방향 확산 과정**:

$$q(I_t|I_{t-1}) = \mathcal{N}(I_t; \sqrt{1-\beta_t}I_{t-1}, \beta_t Z) $$ [1]

**역방향 확산 과정**:

$$p_\theta(I_{t-1}|I_t, I_c) = \mathcal{N}(I_{t-1}; \mu_\theta(I_t, I_c, t), \sigma_t^2 Z) $$ [1]

여기서 평균값은:

$$\mu_\theta(I_t, I_c, t) = \frac{1}{\sqrt{\alpha_t}}(I_t - \frac{\beta_t}{\sqrt{1-\bar{\alpha_t}}}\epsilon_\theta(I_t, I_c, t)) $$[1]

## 3. 모델 구조

### Transformer 분해 네트워크 (TDN)

TDN은 반사도 분해 브랜치와 조명 분해 브랜치로 구성됩니다. 고해상도 영상에서의 어텐션 계산 오버헤드를 해결하기 위해 **Multi-Head Depth-wise Convolutions Layer Attention (MDLA)**를 설계했습니다.[1]

MDLA에서 어텐션 계산은 다음과 같습니다:

$$\hat{X} = \text{softmax}(Q^R K^R / d) \cdot V^R + X $$[1]

### 확산 생성 조정

모델은 두 개의 경로로 구성됩니다:
- **반사도 확산 조정 (RDA)**: RGB 채널 (C=3)
- **조명 확산 조정 (IDA)**: 단일 채널 (C=1)

각 경로는 SR3의 백본을 채택하고 UNet과 어텐션의 특성을 결합한 디노이징 네트워크를 사용합니다.[1]

## 4. 성능 향상 및 한계

### 성능 향상

**정량적 성능**:
- LOL 데이터셋에서 FID 47.85로 최고 성능 달성[1]
- LPIPS 0.048로 지각적 유사성에서 우수한 결과[1]
- VE-LOL-L 데이터셋에서도 종합적으로 최고 성능[1]

**정성적 장점**:
1. **텍스처 완성 및 추론 생성**: 누락된 장면에 대한 텍스처 완성 능력[1]
2. **더 나은 조명 및 색상 충실도**: 색상 편차 문제 해결[1]
3. **선명한 텍스처와 적은 노이즈**: 기존 방법 대비 우수한 디노이징 성능[1]

### 한계

1. **픽셀 수준 오차 지표**: PSNR과 같은 픽셀별 오차 지표에서는 최고 성능을 보이지 않음[1]
2. **계산 복잡도**: 확산 모델의 특성상 추론 시간이 길 수 있음
3. **학습 복잡성**: TDN, RDA, IDA를 순차적으로 학습해야 하는 복잡한 학습 과정

## 5. 일반화 성능 향상 가능성

### 일반화 성능 요소

**크로스 데이터셋 성능**: LOL, VE-LOL-L, DICM 데이터셋에서 일관되게 우수한 성능을 보여 강한 일반화 능력을 입증했습니다.[1]

**물리적 해석 가능성**: Retinex 모델의 물리적 기반과 생성 모델의 장점을 결합하여 다양한 저조도 조건에서 적응할 수 있는 견고성을 제공합니다.[1]

**Transformer 기반 글로벌 정보 활용**: CNN의 한계를 극복하고 전역 정보를 활용하여 다양한 해상도와 장면에 대한 적응성을 향상시켰습니다.[1]

## 6. 앞으로의 연구 영향 및 고려사항

### 연구에 미치는 영향

1. **패러다임 전환**: 저조도 영상 향상을 복원에서 생성으로 접근하는 새로운 패러다임 제시
2. **확산 모델의 새로운 응용**: 확산 모델과 물리 기반 모델의 결합 가능성 확장
3. **멀티모달 접근법**: 조명과 반사도의 다중 경로 처리 방식의 응용 확장

### 앞으로 고려할 점

**기술적 개선 방향**:
1. **효율성 개선**: 확산 모델의 추론 속도 향상을 위한 연구 필요
2. **픽셀 수준 정확도**: 생성 품질과 픽셀 정확도의 균형점 탐색
3. **통합 학습**: 세 모듈의 end-to-end 학습 방법 개발

**응용 확장 가능성**:
1. **실시간 처리**: 모바일 기기나 실시간 시스템에서의 적용
2. **다른 열화 조건**: 안개, 비, 눈 등 다른 기상 조건에서의 영상 향상
3. **의료 영상**: 저조도 의료 영상 처리에서의 응용 가능성

이 연구는 생성형 AI를 활용한 영상 복원 분야에서 중요한 이정표를 제시하며, 특히 물리 기반 모델과 생성 모델의 융합이라는 새로운 연구 방향을 제시한 점에서 큰 의미를 가집니다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/1ce57a67-18d6-43da-a0b4-937954655416/2308.13164v1.pdf)
