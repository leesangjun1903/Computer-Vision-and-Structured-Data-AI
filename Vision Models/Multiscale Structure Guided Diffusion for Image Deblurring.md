# Multiscale Structure Guided Diffusion for Image Deblurring

### 1. 핵심 주장과 주요 기여

**핵심 주장**

이 논문은 Image-conditioned Diffusion Probabilistic Models (icDPMs)가 학습 데이터와 다른 도메인의 이미지에 적용될 때 일반화 성능이 저하되는 문제를 해결하기 위해, **다중 스케일 구조 가이던스(Multiscale Structure Guidance)**를 제안합니다. 기존 icDPM은 단순히 입력 레벨에서 흐릿한 이미지를 연결(concatenation)하는 방식으로 조건화하는데, 이는 중간 단계에서 제약이 없어 도메인 변화에 취약하고 아티팩트를 생성하는 문제가 있습니다.[1]

**주요 기여**

1. **도메인 일반화 분석**: 모션 디블러링 작업에서 조건부 확산 모델의 도메인 일반화 문제를 조사하고, 모델의 강건성과 이미지 조건화 메커니즘 간의 관계를 실증적으로 규명했습니다.[1]

2. **다중 스케일 구조 가이던스**: 입력 이미지를 다중 스케일 구조 표현으로 투영하는 직관적이면서도 효과적인 가이던스 모듈을 제안하여, 확산 모델을 더욱 강건하게 만들었습니다.[1]

3. **최첨단 성능**: 단일 데이터셋(GoPro)으로 학습한 모델이 다양한 테스트 세트에서 더 신뢰할 수 있는 디블러링 결과를 생성하며, 최첨단 지각 품질과 경쟁력 있는 왜곡 메트릭을 달성했습니다.[1]

---

### 2. 문제 정의, 제안 방법, 모델 구조, 성능 및 한계

#### **2.1 해결하고자 하는 문제**

**문제 배경**

- 이미지 디블러링은 흐릿한 관측값으로부터 선명한 고품질 이미지를 복원하는 ill-posed 역문제입니다.[1]
- 딥러닝 기반 회귀 방법은 PSNR과 같은 왜곡 메트릭을 최적화하지만 과도하게 부드러운 출력을 생성하여 시각적 충실도가 떨어집니다.[1]
- GAN 기반 방법은 더 나은 지각 품질을 제공하지만 훈련 불안정성, 모드 붕괴, 아티팩트 문제가 있습니다.[1]
- 최근 icDPMs은 사실적인 결과를 생성하지만, 학습 도메인과 다른 out-of-domain 데이터에 대한 강건성이 불분명합니다.[1]

**핵심 문제**

기존 icDPMs는 입력 레벨 연결만으로 조건화하고 중간 제약이 없어, 합성 학습 데이터에 과적합되고 실제 도메인으로의 일반화에 실패합니다. 저자들은 이를 "naive input-level concatenation"과 "lack of intermediate constraints"로 인한 도메인 민감성 문제로 규정했습니다.[1]

#### **2.2 제안하는 방법**

**방법론 개요**

저자들은 전통적인 blind deblurring 알고리즘에서 명시적 구조 프라이어(예: 이미지 현저성)를 사용하는 것에서 영감을 받아, icDPM의 UNet 백본에 **중간 레이어에서 다중 스케일 구조 가이던스**를 통합했습니다.[1]

**수식 포함 상세 설명**

**(1) Diffusion Probabilistic Model 기초**

확산 과정에서 시간 단계 $$t$$에서 노이즈가 추가된 이미지는 다음과 같이 생성됩니다:[1]

$$
\mathbf{x}_t = \sqrt{\alpha_t}\mathbf{x} + \sqrt{1 - \alpha_t}\boldsymbol{\epsilon}, \quad \boldsymbol{\epsilon} \sim \mathcal{N}(0, \mathbf{I})
$$

여기서 $$\alpha_t$$는 각 단계에서 추가되는 노이즈의 양을 제어합니다.

역과정에서는 UNet $$\mathcal{G}_\theta(\mathbf{x}_t, \mathbf{y}, t)$$가 부분적으로 노이즈가 있는 입력 $$\mathbf{x}_t$$로부터 깨끗한 이미지를 추정합니다. 실제로는 노이즈 $$\boldsymbol{\epsilon}$$을 예측하도록 재매개변수화됩니다.[1]

**(2) 다중 스케일 구조 가이던스**

스케일 $$k$$에서 가이던스는 $$h_k(\cdot) = \mathcal{H}(\phi_k(\cdot))$$로 구성됩니다:[1]

- **이미지 변환 함수** $$\phi_k(\cdot)$$: 입력 이미지를 그레이스케일로 변환하고 $$2^k$$ (k=1,2,3)만큼 다운샘플링하여 블러 흔적을 제거하면서 거친 구조를 보존합니다:[1]

$$
\phi_k(\mathbf{y}) = d_{\downarrow k}(\bar{\mathbf{y}}) + \mathbf{n}, \quad \mathbf{n} \sim \mathcal{N}(0, \sigma^2 \mathbf{I})
$$

여기서 $$\bar{\mathbf{y}}$$는 그레이스케일 이미지이고, $$\mathbf{n}$$은 도메인 특정 특성을 마스킹하기 위한 작은 가우시안 노이즈입니다.[1]

- **가이던스 네트워크**

$$\mathcal{H}\_\varphi$$: $$\phi_k(\mathbf{y})$$를 잠재 공간으로 매핑하여 가이던스 특징 $$h_k(\mathbf{y}) = \mathcal{H}_\varphi(\phi_k(\mathbf{y}))$$를 추출합니다.[1]

- **회귀 작업**: 가이던스가 선명한 구조 정보를 유지하도록 회귀 레이어 $$\mathcal{R}_\varphi$$를 적용하여 출력이 선명한 타겟 $$\phi_k(\mathbf{x})$$에 가깝도록 제약합니다.[1]

**(3) 학습 손실 함수**

**회귀 손실** (스케일 $$k$$별):[1]

```math
\mathcal{L}_{\text{guidance}}^k = \mathbb{E}_{(\mathbf{x}, \mathbf{y}) \sim p_{\text{train}}} \|\mathcal{R}_{\varphi}(\mathcal{H}_{\varphi}(\phi_k(\mathbf{y}))) - \phi_k(\mathbf{x})\|_2
```

전체 회귀 손실은 $$\mathcal{L}\_{\text{guidance}} = \sum_k \mathcal{L}_{\text{guidance}}^k$$입니다.[1]

**디노이징 손실**:[1]

$$
\mathcal{L}_{\text{DPM}} = \mathbb{E}_{(\mathbf{x}, \mathbf{y}) \sim p_{\text{train}}} \mathbb{E}_{t \sim \text{Unif}(0,1)} \mathbb{E}_{\boldsymbol{\epsilon} \sim \mathcal{N}(0, \mathbf{I})} \|\mathcal{G}_{\theta}(\mathbf{x}_t, \mathbf{y}, \{\mathcal{H}_{\varphi}(\phi_k(\mathbf{y}))\}, \alpha_t) - \boldsymbol{\epsilon}\|_1
$$

**전체 손실**: $$\mathcal{L} = \mathcal{L}\_{\text{guidance}} + \mathcal{L}_{\text{DPM}}$$로, 가이던스 네트워크 $$\mathcal{H}$$, 회귀 레이어 $$\mathcal{R}$$, icDPM $$\mathcal{G}$$를 end-to-end로 최적화합니다.[1]

#### **2.3 모델 구조**

**전체 아키텍처**:[1]

1. **icDPM 백본**: 완전 합성곱 UNet 구조로, 임의 해상도의 이미지에 사용 가능합니다.
2. **가이던스 네트워크**: 
   - 입력을 그레이스케일 변환 및 다운샘플링
   - 여러 ResBlocks을 통해 특징 추출
   - 각 스케일에서 마지막 ResBlock의 출력을 가이던스 특징으로 사용
3. **Guided ResBlocks**: UNet 인코더의 표준 ResBlock을 Guided ResBlock으로 대체하여 각 스케일에서 가이던스 특징을 addition 연산으로 통합합니다.[1]

**학습 세부사항**:[1]
- TensorFlow 2.0, 32 TPU v3 코어
- Adam 옵티마이저 (β₁=0.5, β₂=0.999)
- 배치 크기 256, 128×128 랜덤 크롭
- 처음 60k 반복에서 회귀 손실로 warm start 후 디노이징 손실 가중치를 점진적으로 증가
- 학습률: 처음 20k 반복에서 선형 증가, 이후 1×10⁻⁴로 고정

#### **2.4 성능 향상**

**정량적 결과**

*In-domain (GoPro) 성능*:[1]
- LPIPS: 0.057 (최고), PSNR: 31.19 
- 모든 지각 메트릭(LPIPS, NIQE, FID, KID)에서 최첨단 성능 달성

*Out-of-domain 성능*:[1]

**Realblur-J (가장 큰 도메인 갭)**:
- LPIPS: 0.123 (최고), FID: 8.41, KID: 2.39
- UFormer (0.140 LPIPS), Restormer (0.149 LPIPS)보다 크게 우수

**HIDE**:
- LPIPS: 0.088, PSNR: 29.14
- 아티팩트 감소 및 일관된 성능

**REDS**:
- LPIPS: 0.123, PSNR: 28.56
- 강력한 블러 제거 능력

**4개 데이터셋 평균 성능**:[1]
- LPIPS: 0.104 (최고), NIQE: 2.94, FID: 8.41, KID: 2.39
- 샘플 평균(Ours-SA) 사용 시 PSNR: 29.98로 경쟁력 유지

**사용자 연구**:[1]
- Realblur-J에서 25명의 평가자, 750개 평가
- 제안 방법이 기존 솔루션보다 선호도 높음 (예: UFormer 대비 65%, icDPM 대비 62%)

**정성적 결과**:[1]
- GoPro (in-domain): 모든 방법이 합리적인 디블러링 수행, 제안 방법이 더 선명하고 사실적
- Out-of-domain: GAN 기반(DeblurGAN-v2)과 이전 확산 기반(DvSR) 방법은 아티팩트 생성, 회귀 기반(UFormer)은 과도하게 부드러운 결과 생성
- 제안 방법: 다양한 데이터셋에서 일관되게 우수한 성능, 아티팩트 감소, 높은 지각 사실성

#### **2.5 한계**

**학습 데이터의 품질 제약**:[1]
- 모델의 일반화 능력은 궁극적으로 학습 데이터의 품질과 사실성에 제한됨
- GoPro 데이터셋은 주간 야외 장면만 포함, 저조도나 포화 영역 등 실제 시나리오를 충분히 커버하지 못함
- GoPro의 블러 합성 방법(연속 프레임 평균)이 비현실적

**실패 사례**:[1]
- 저조도 야간 장면, 강한 빛 줄무늬가 있는 이미지에서 모든 방법이 실패
- 부록의 Realblur-J 실패 사례들에서 야간 장면 디블러링에 어려움 확인

**방법론적 제한**:[1]
- 회귀 목표로 학습되는 가이던스 모듈을 회귀 모델에 적용하면 단순히 파라미터가 증가한 단일 모델이 될 수 있음
- Transformer 등 다른 최첨단 백본에 가이던스를 적용하는 확장은 추가 연구 필요

**계산 비용**:[1]
- 샘플링 속도 최적화는 본 연구 범위 밖
- 최근 DPM 샘플링 가속화 기법을 통합 가능할 것으로 예상

***

### 3. 일반화 성능 향상 메커니즘

#### **3.1 도메인 불변성 분석**

**Inception Distance 분석**:[1]
- GoPro와 Realblur-J 간 FID/KID를 다양한 스케일에서 측정
- 각 스케일(×2, ×4, ×8)에서 가이던스 네트워크 출력이 다운샘플된 입력 대비 일관되게 FID/KID 감소
- 예: ×8 다운샘플 공간에서 FID 49.684→44.649, KID 4.91→4.70

이는 학습된 가이던스가 **도메인 불가지론적(domain-agnostic) 정보를 제공하여 보지 못한 도메인에서의 일반화**에 기여함을 입증합니다.[1]

#### **3.2 가이던스 설계 원칙과 일반화**

**(1) 그레이스케일 변환**:[1]
- RGB 정보 제거로 색상 관련 도메인 특성 억제
- 구조 정보에만 집중

**(2) 다운샘플링**:[1]
- 미세한 디테일(블러 흔적 포함) 제거
- 여러 낮은 해상도에서 거친 구조 보존

**(3) 노이즈 추가**:[1]
- 도메인 특정 열화/특성 마스킹
- 최근 확산 모델에서 out-of-domain 데이터 처리 시 강건성 향상을 위한 일반적 관행

**(4) 다중 스케일 접근**:[1]
- 단일 스케일(0.141 LPIPS) 대비 다중 스케일(0.137 LPIPS)에서 성능 향상
- 다양한 레벨의 구조 정보를 계층적으로 제공

#### **3.3 모델 용량과 일반화의 균형**

**실험 결과**:[1]
- 가이던스 없이 큰 icDPM(icDPM-L): in-domain 성능 향상(PSNR 32.105), out-of-domain 성능 저하(LPIPS 0.156)
- 가이던스 추가 시: in-domain(PSNR 32.220) 및 out-of-domain(LPIPS 0.128) 모두 향상
- 과적합 방지 및 시각적 아티팩트 감소

이는 가이던스가 **단순한 파라미터 증가가 아닌 효과적인 조건화 메커니즘**으로 작동함을 보여줍니다.[1]

#### **3.4 채널별 가이던스 특징 시각화**

Figure 9에서 64개 채널 중 12개 선택 채널의 가이던스 특징맵 분석:[1]
- 엣지 및 전체 구조와 높은 관련성
- icDPM에 선명한 복원의 거친 구조에 대한 보조 정보 제공
- 모델 강건성 향상에 기여

***

### 4. 향후 연구에 미치는 영향 및 고려사항

#### **4.1 향후 연구에 미치는 영향**

**1. 조건부 확산 모델 설계 패러다임 전환**
- 입력 레벨 조건화의 한계를 입증하고, **중간 레이어에서의 구조화된 가이던스**의 중요성을 강조[1]
- 다른 이미지 복원 작업(super-resolution, denoising, inpainting)으로 확장 가능

**2. 도메인 일반화 연구 방향**
- 명시적 도메인 적응 없이 **암묵적 편향(implicit bias)**을 통한 강건성 향상 방법론 제시[1]
- 대규모 현실 데이터 필요성과 모델 일반화 능력 개선의 상호보완적 접근 가능성 시사

**3. 전통적 방법과 딥러닝의 융합**
- 전통적인 구조 프라이어(structural priors) 개념을 학습 기반 가이던스로 재해석[1]
- Classical vision과 deep learning의 효과적 결합 사례

**4. 확산 모델의 조건화 메커니즘 연구**
- 현재 under-explored 상태인 손상된 이미지에 대한 확산 모델 조건화[1]
- ControlNet, InDI 등 후속 연구와 비교 가능한 벤치마크 제공

#### **4.2 앞으로 연구 시 고려할 점**

**1. 학습 데이터 다양성 확보**[1]
- 더 현실적이고 다양한 학습 데이터셋 구축
- 저조도, 야간, 포화 영역 등 극단적 조건 포함
- 최근 연구(Realistic blur synthesis 등)와 결합 가능

**2. 다른 백본 아키텍처와의 통합**[1]
- Transformer 기반 아키텍처(Vision Transformer, Swin Transformer)에 가이던스 적용
- 회귀 모델에 가이던스 적용 시 단순 파라미터 증가가 아닌 효과적 통합 방법 연구 필요

**3. 샘플링 효율성 개선**
- DPM-Solver, DDIM, Genie 등 최근 가속화 기법 통합[1]
- 실시간 또는 준실시간 처리를 위한 경량화

**4. 다른 역문제로의 확장**
- Super-resolution: 이미 SRDiff 등에서 시도되었으나 가이던스 통합 가능[1]
- JPEG 복원, video deblurring 등
- 의료 영상 등 특수 도메인 적용

**5. 손실 함수 설계**
- 회귀 손실의 필수성 입증: 제거 시 PSNR 31.19→30.56[1]
- 다른 구조 프라이어(edge maps, segmentation masks) 통합 가능성
- Perceptual loss, adversarial loss와의 조합 실험

**6. 도메인 적응 전략**
- 부록에서 adversarial domain adaptation 실험이 오히려 성능 저하 확인[1]
- GAN 학습 불안정성 또는 icDPM 프레임워크 내 차최적 공식화 문제
- 더 안정적인 도메인 적응 방법 탐구 필요

**7. 지각-왜곡 트레이드오프 분석**[1]
- Figure 5에서 샘플링 파라미터에 따른 perception-distortion 곡선 확인
- 응용에 따른 최적 균형점 설정 방법론 연구

**8. 계산 효율성과 실용성**
- Table 13의 FLOPs 분석: icDPM-L w/ Guide-L이 10000B FLOPs[1]
- 모바일/엣지 디바이스 배포를 위한 경량화 연구
- Knowledge distillation, pruning, quantization 적용

**9. 평가 메트릭 재고**
- 저자들이 지적한 PSNR/SSIM의 인간 지각과의 낮은 상관관계[1]
- LPIPS, FID, KID 등 지각 메트릭 중심 평가의 중요성
- 사용자 연구(Table 8)와 같은 인간 평가 확대

**10. 윤리적 고려사항**
- 생성 모델의 memorization 문제[1]
- 학습 데이터 편향이 일반화에 미치는 영향
- 실제 응용에서의 공정성 및 투명성 확보

***

### 결론

이 논문은 **다중 스케일 구조 가이던스를 통한 이미지 조건부 확산 모델의 도메인 일반화 향상**이라는 중요한 문제를 해결했습니다. 전통적 구조 프라이어에서 영감을 받은 학습 기반 가이던스를 중간 레이어에 통합하여, 단일 데이터셋으로 학습한 모델이 다양한 보지 못한 데이터에서 강건한 디블러링 성능을 달성했습니다.[1]

특히 **일반화 성능 측면**에서, 가이던스가 도메인 불가지론적 정보를 제공하고(Inception distance 감소), 과적합을 방지하며(큰 모델에서도 out-of-domain 성능 향상), 구조적 제약을 통해 확산 과정을 안정화시킨다는 것을 입증했습니다.[1]

향후 연구는 더 다양한 학습 데이터 확보, 다양한 백본 아키텍처와의 통합, 샘플링 효율성 개선, 다른 역문제로의 확장 등을 고려해야 하며, 이 연구는 조건부 생성 모델의 강건성 향상을 위한 중요한 이정표가 될 것입니다.[1]

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/27d74213-7e0e-4b49-899b-d3174b5481d9/2212.01789v3.pdf)
