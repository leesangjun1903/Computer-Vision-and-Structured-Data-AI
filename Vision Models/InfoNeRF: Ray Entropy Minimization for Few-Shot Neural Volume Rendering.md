# InfoNeRF: Ray Entropy Minimization for Few-Shot Neural Volume Rendering

### 핵심 주장과 주요 기여

**InfoNeRF**는 정보 이론(Information Theory) 기반의 정규화 기법으로 few-shot (소수 장면) 신경 부피 렌더링에 혁신을 가져온 논문입니다. 핵심 주장은 불충분한 시점(viewpoint)으로 인해 발생하는 **재구성 불일치(reconstruction inconsistency)**와 **과적합(overfitting)** 문제를 각 광선(ray)의 엔트로피 최소화와 정보 이득 감소를 통해 해결할 수 있다는 것입니다.[1]

주요 기여는 다음과 같습니다:[1]
- 신경 암묵적 표현(neural implicit representation)의 정규화를 위한 새로운 정보 이론적 접근 방식 제안
- 두 가지 효과적인 정규화 체계 도입: ray 엔트로피 최소화 및 ray 정보 이득 감소
- 외부 데이터 구조(복셀, 메시)나 추가 학습 가능한 매개변수 없이 다양한 신경 부피 렌더링 알고리즘에 적용 가능한 범용 기법 제시

***

### 해결하는 문제와 제안 방법

#### 1. 문제 정의

Few-shot NeRF는 두 가지 근본적 문제를 마주합니다:[1]

첫째, **재구성 불일치**: 적은 수의 훈련 이미지로 인해 3D 깊이 추정에 심각한 노이즈가 발생하며, 이는 렌더링된 이미지의 노이즈, 흐림, 인공물(artifact)로 나타납니다.

둘째, **과적합 문제**: 훈련 장면에 극도로 과적합되어 약간 다른 시점에서 완전히 다른 렌더링 결과를 생성합니다.

#### 2. 제안 방법

**기본 NeRF 렌더링 방정식**

NeRF의 기본 렌더링은 다음과 같이 표현됩니다:[1]

$$\hat{C}(\mathbf{r}) = \sum_{i=1}^{N}T_i(1-\exp(-\sigma_i\delta_i))\mathbf{c}_i$$

여기서:
- $\mathbf{r}$: 광선
- $N$: 샘플 포인트 수
- $\delta_i$: i번째 포인트와 인접한 샘플 간 거리
- $T_i$: i번째 포인트까지의 누적 투과율(accumulated transmittance)로 다음과 같이 정의됨:[1]

$$T_i = \exp\left(-\sum_{j=1}^{i-1}\sigma_j\delta_j\right)$$

**Ray Density 정의**

정규화된 광선 밀도 $p(\mathbf{r}_i)$를 다음과 같이 정의합니다:[1]

$$p(\mathbf{r}_i) = \frac{\alpha_i}{\sum_j\alpha_j} = \frac{1-\exp(-\sigma_i\delta_i)}{\sum_j(1-\exp(-\sigma_j\delta_j))}$$

여기서:
- $\sigma_i$: i번째 포인트에서의 밀도
- $\delta_i$: 샘플링 간격
- $\alpha_i = 1-\exp(-\sigma_i\delta_i)$: i번째 포인트의 불투명도(opacity)

**Ray Entropy Minimization Loss**

Shannon 엔트로피를 기반으로 광선의 엔트로피를 정의합니다:[1]

$$H(\mathbf{r}) = -\sum_{i=1}^{N}p(\mathbf{r}_i)\log p(\mathbf{r}_i)$$

관찰된 광선만 처리하기 위해 마스크 변수를 도입합니다:[1]

$$M(\mathbf{r}) = \begin{cases} 1 & \text{if } Q(\mathbf{r}) > \epsilon \\ 0 & \text{otherwise} \end{cases}$$

여기서 누적 광선 밀도(cumulative ray density)는:[1]

$$Q(\mathbf{r}) = \sum_{i=1}^{N}(1-\exp(-\sigma_i\delta_i))$$

Ray entropy loss는 다음과 같이 정의됩니다:[1]

$$\mathcal{L}_{\text{entropy}} = \frac{1}{|\mathcal{R}_s| + |\mathcal{R}_u|}\sum_{\mathbf{r} \in \mathcal{R}_s \cup \mathcal{R}_u} M(\mathbf{r}) \odot H(\mathbf{r})$$

여기서:
- $\mathcal{R}_s$: 훈련 이미지로부터의 광선 집합
- $\mathcal{R}_u$: 무작위로 샘플링된 미관측 이미지로부터의 광선 집합
- $\odot$: 요소별 곱셈(element-wise multiplication)

**Ray Information Gain Reduction Loss (KL Divergence Loss)**

과적합을 방지하기 위해 약간 다른 시점의 광선 쌍 사이의 KL 발산을 최소화합니다:[1]

$$\mathcal{L}_{\text{KL}} = D_{\text{KL}}(P(\mathbf{r}) \| P(\tilde{\mathbf{r}})) = \sum_{i=1}^{N}p(\mathbf{r}_i)\log\frac{p(\mathbf{r}_i)}{p(\tilde{\mathbf{r}_i})}$$

여기서 $\tilde{\mathbf{r}}$는 카메라 포즈를 -5°에서 5° 범위 내에서 약간 회전시킨 관측점입니다.[1]

#### 3. 전체 손실 함수

최종 손실 함수는:[1]

$$\mathcal{L}_{\text{total}} = \mathcal{L}_{\text{RGB}} + \lambda_1 \mathcal{L}_{\text{entropy}} + \lambda_2 \mathcal{L}_{\text{KL}}$$

여기서 RGB 재구성 손실은:[1]

$$\mathcal{L}_{\text{RGB}} = \frac{1}{|\mathcal{R}_s|}\sum_{\mathbf{r}\in\mathcal{R}_s} \|C(\mathbf{r}) - \hat{C}(\mathbf{r})\|_2^2$$

여기서:
- $\lambda_1$, $\lambda_2$: 정규화 계수(balancing terms)
- $C(\mathbf{r})$: 실제 광선 색상
- $\hat{C}(\mathbf{r})$: 예측된 광선 색상

***

### 모델 구조

InfoNeRF는 **플러그-인 정규화 기법**으로 설계되어 기존 NeRF 기반 방법들에 직접 통합됩니다. 특정 아키텍처를 요구하지 않으며, 다음과 같은 특징을 가집니다:[1]

- **효율성**: 3D 복셀 엔트로피 기반 방법과 달리 1D 광선 샘플링을 사용하므로 매우 효율적
- **범용성**: 외부 데이터 구조나 사전 학습된 모델 없이 NeRF 기반 체적 렌더링 알고리즘에 적용 가능
- **단순성**: 추가 학습 가능한 매개변수를 도입하지 않음

광선 엔트로피 최소화는 "가장 덜 노이즈가 있는" 또는 "가장 덜 무질서한" 배치를 찾는 것으로 이해할 수 있으며, KL 발산 손실은 오버피팅을 방지합니다.[1]

***

### 성능 향상

**실험 결과**

InfoNeRF는 표준 벤치마크에서 기존 방법들을 큰 폭으로 능가합니다:[1]

Realistic Synthetic 360° 데이터셋의 4-view 설정에서:[1]

| 방법 | PSNR ↑ | SSIM ↑ | LPIPS ↓ | FID ↓ | KID ↓ |
|------|--------|--------|---------|-------|-------|
| NeRF (100 views) | 31.01 | 0.947 | 0.081 | 42.83 | 0.002 |
| PixelNeRF* | 16.09±0.78 | 0.738±0.012 | 0.390±0.030 | 265.25±6.73 | 0.127±0.006 |
| NeRF (4 views) | 15.93±1.06 | 0.780±0.014 | 0.320±0.049 | 215.16±2.32 | 0.074±0.012 |
| DietNeRF | 16.06±1.13 | 0.793±0.019 | 0.306±0.050 | 197.02±12.87 | 0.065±0.004 |
| **InfoNeRF (ours)** | **18.65±0.18** | **0.811±0.008** | **0.230±0.008** | **181.47±4.97** | **0.062±0.004** |

**정규화 기법의 효과 분석**

Ablation study 결과:[1]

| 방법 | Entropy Loss | KL Loss | PSNR↑ | SSIM↑ | LPIPS↓ |
|------|---|---|--------|-------|----------|
| NeRF | ✗ | ✗ | 8.50 | 0.426 | 0.611 |
| InfoNeRF w/o $\mathcal{L}_{\text{entropy}}$ | ✗ | ✓ | 8.91 | 0.439 | 0.581 |
| InfoNeRF w/o $\mathcal{L}_{\text{KL}}$ | ✓ | ✗ | 10.54 | 0.418 | 0.561 |
| **InfoNeRF** | **✓** | **✓** | **11.23** | **0.445** | **0.543** |

설계된 손실이 제대로 반영되었음을 증명: InfoNeRF(4-view)가 NeRF(100-view)와 유사한 수준으로 엔트로피와 정보 이득을 감소시킵니다.[1]

***

### 모델의 일반화 성능 향상

#### 1. 장면 간 일관성

InfoNeRF의 핵심 강점은 **공간적 평활성(spatial smoothness)** 제약을 통해 인접한 광선들 간 렌더링 일관성을 강화합니다. 이를 통해:[1]

- 인접한 시점 사이의 급격한 변화 방지
- 기하학적 불연속성 감소
- 세계 공간에서 일관된 3D 기하학 학습

#### 2. 노이즈 감소

엔트로피 최소화는 확률 분포를 단봉형(unimodal)으로 만들어 각 광선을 따라 밀도 함수를 더 스파스(sparse)하게 합니다. 이는:[1]

- 깊이 추정의 모호성 감소
- 렌더링된 깊이 맵의 노이즈 감소
- 객체 경계의 명확성 향상

#### 3. 과적합 방지

KL 발산 손실을 통해 유사한 시점들 간의 확률 분포를 강제로 정렬하므로:

- 훈련 시점에 대한 과도한 적합 방지
- 새로운 시점에 대한 일반화 능력 향상
- 텍스처 없는 영역에서의 안정성 개선

미관측 시점 광선의 활용:[1]

unseen view로부터의 광선을 추가로 활용하면 성능이 점진적으로 개선됩니다:

| 광선 수 | PSNR ↑ | SSIM ↑ | LPIPS ↓ |
|---------|--------|--------|---------|
| 보임 1024, 미관측 0 | 20.14 | 0.834 | 0.225 |
| 보임 1024, 미관측 256 | 20.97 | 0.844 | 0.197 |
| 보임 1024, 미관측 512 | 21.11 | 0.851 | 0.188 |
| 보임 1024, 미관측 1024 | 21.37 | 0.853 | 0.185 |
| 보임 1024, 미관측 2048 | 21.33 | 0.855 | 0.167 |

1,024개 이상의 광선에서 포화 효과가 나타납니다.[1]

#### 4. 사전 지식 없는 일반화

InfoNeRF의 또 다른 장점은 **장면에 대한 사전 지식이 필요 없다는 것**입니다. 이는:[1]

- 다양한 장면과 물체에 적용 가능
- 특정 도메인이나 객체 카테고리에 제한되지 않음
- 새로운 도메인에 쉽게 전이 가능

#### 5. 견고성 분석

훈련 시점 수에 따른 성능:[1]

InfoNeRF는 8개 시점까지 NeRF에 비해 지속적인 개선을 보이며, 이후로는 효과가 포화됩니다. 이는 불확실성이 감소함에 따라 엔트로피 정규화의 중요성이 감소함을 시사합니다.[1]

***

### 한계

논문의 주요 한계는 다음과 같습니다:[1]

1. **메트릭 간 트레이드오프**: 일부 데이터셋(특히 DTU)에서 PSNR 개선이 SSIM 악화로 이어질 수 있음. 이는 엔트로피 최소화가 때로 과도하게 제약을 가할 수 있음을 시사합니다.[1]

2. **하이퍼파라미터 민감성**: $\lambda_1$, $\lambda_2$ 값의 선택이 데이터셋별로 다를 수 있으며, 특히 $\lambda_2$는 5,000 반복마다 2배씩 감소하는 동적 감쇠 스케줄링이 필요합니다.[1]

3. **극단적 Few-shot 시나리오**: 1-2 이미지만 사용하는 경우 성능 제한이 있습니다.[1]

4. **동적 장면 미지원**: 정적 장면만 가정하므로 동적 장면에는 적용 불가능합니다.[1]

5. **깊이 정확성**: 완벽한 깊이 재구성보다는 일관성에 중점을 두므로, 절대 깊이 값의 정확성은 보장하지 않습니다.[1]

6. **카메라 캘리브레이션 필요**: 비록 적은 수의 이미지만 필요하지만, 정확한 카메라 포즈 정보는 여전히 필요합니다.[1]

***

### 최신 연구 및 영향

#### 1. 후속 연구

InfoNeRF 이후 few-shot NeRF 분야는 다음과 같은 방향으로 발전하고 있습니다:[2][3][4][5][6][7][8]

**정규화 기반 방법들의 진화**:[8]
- **DWTNeRF** (2025): 이산 웨이블릿 변환을 활용하여 저주파와 고주파를 명시적으로 분해[2][8]
- **CombiNeRF** (2024): 다양한 정규화 기법을 조합[5]
- **GeCoNeRF** (2023): 기하학적 일관성 정규화[3]
- **SGCNeRF** (2024): 특징 매칭 기반 희소 기하학 정규화[4]

**주파수 제어 기반 접근**:[6][7][9]
- **FreeNeRF** (2023): 주파수 정규화와 카메라 근처 밀도 제약[9]
- **AR-NeRF** (2024): 위치 인코딩(PE) 주파수 정규화[7]
- **SANeRF** (2024): 공간 어닐링으로 효율성 개선[6]

**깊이 기반 사전 접근**:[10][11][12]
- **SparseNeRF** (2023): 로컬 깊이 순위 제약 추출[11][12]
- **DASNeRF** (2025): 깊이 일관성 최적화와 적응형 샘플링[13]

**기타 혁신적 접근**:[14][15]
- **NeuGen** (2024-2025): 뇌 영감적 정규화로 도메인 불변 특징 추출[14]
- **데이터 증강**: 불확실성 분포에서의 거부 샘플링으로 저데이터 한계 극복[15]

#### 2. 일반화 성능 개선의 최신 방향

**도메인 간 일반화**:[14]
최신 연구(2024-2025)는 **단일 장면 최적화를 넘어 교차 장면 일반화**에 초점을 맞추고 있습니다. NeuGen과 같은 방법들은 생물학적 시각 피질에 영감을 받은 Winner-Takes-All(WTA) 메커니즘을 활용하여 도메인 불변 특징을 추출하고, 다양한 데이터셋에서 일관된 성능을 제공합니다.[14]

**사전 지식 통합의 한계**:[16]
흥미로운 발견으로, DINO와 같은 사전 학습된 비전 특징이 오히려 few-shot NeRF 성능을 악화시킬 수 있다는 것이 보고되었습니다. 이는 **기하학적 일관성에 초점을 맞춘 더 단순한 아키텍처**가 더 효과적일 수 있음을 시사합니다.[16]

**불확실성 기반 접근**:[15]
저데이터 한계에서 볼륨 불확실성 추정기를 활용한 후 거부 샘플링으로 시점 증강을 수행하면, 기존 방법 대비 평균 39.9% 성능 개선을 달성할 수 있습니다.[15]

#### 3. 향후 연구 시 고려사항

**1) 적응형 하이퍼파라미터 조정**

$$\lambda_i(t) = \lambda_i^0 \cdot \exp(-t/\tau)$$

와 같은 동적 스케줄링을 통해 훈련 단계에 따라 정규화 가중치를 자동으로 조정합니다.

**2) 극단적 Few-shot 시나리오 대응**
- 1-3 이미지 기반 재구성을 위한 강화된 사전(prior) 통합
- InfoNeRF와 깊이 기반 방법(SparseNeRF, DASNeRF)의 계층적 결합

**3) 교차 장면 사전 학습**
- 소수 시점에서 학습 가능한 일반화된 NeRF 인코더 개발
- NeuGen 같은 도메인 불변 특징 추출과 정보 이론적 정규화의 융합

**4) 불확실성 정량화**
- 렌더링된 이미지와 깊이 예측에 대한 신뢰 구간 제공
- 베이지안 프레임워크를 통한 OOD(Out-of-Distribution) 감지

**5) 계산 효율성**
- Instant-NGP와 같은 빠른 인코딩 방법과 InfoNeRF의 호환성 개선
- 멀티 스케일 해시 그리드에 최적화된 엔트로피 기반 정규화

**6) 실제 응용 확대**
- 카메라 포즈 불확실성 처리를 위한 robust한 framework 개발
- 동적 장면 및 시간 변화 조명으로 확장
- 로봇 비전, AR/VR 등에서의 실시간 적용

#### 4. 이론적 기여

InfoNeRF는 단순한 방법을 넘어 **정보 이론을 3D 시각 문제에 적용하는 새로운 패러다임**을 제시했습니다. 이는:

- 신경 부피 렌더링에서 **엔트로피 최소화의 역할**에 대한 이해 증진
- **광선 단위의 지역적 제약**이 전역적 일관성을 달성하는 메커니즘 규명
- 정보 이론적 정규화 기법의 일반적 원리 확립

이러한 통찰은 후속 연구에서 주파수 제어, 기하학적 제약, 불확실성 정량화 등으로 발전되고 있습니다.[3][4][7][2][6][14]

---

### 결론

**InfoNeRF**는 정보 이론의 우아한 원리를 few-shot 신경 부피 렌더링에 적용하여 혁신적 성과를 달성했습니다. 엔트로피 최소화 손실 $\mathcal{L}\_{\text{entropy}}$와 KL 발산 손실 $\mathcal{L}\_{\text{KL}}$의 조합을 통해 불충분한 시점 정보라는 근본적 제약을 효과적으로 해결했으며, 외부 사전 지식 없이도 우수한 성능을 달성합니다.[1]

후속 연구들은 주파수 제어, 깊이 기반 제약, 도메인 일반화 등 다양한 방향으로 발전을 거듭하고 있습니다. 특히 극단적 저데이터 환경에서의 안정적 학습과 교차 장면 일반화라는 도전에 직면하여, **정보 이론적 정규화와 깊이 사전의 지능적 결합**, 그리고 **생물학적 영감의 도입**이 차세대 few-shot 3D 재구성 방법의 핵심이 될 것으로 예상됩니다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/9dd3261e-8562-4ffa-b0a2-0cf4f8e943b9/2112.15399v2.pdf)
[2](https://arxiv.org/html/2501.12637v2)
[3](https://arxiv.org/abs/2301.10941)
[4](http://arxiv.org/pdf/2404.00992.pdf)
[5](http://arxiv.org/pdf/2403.14412.pdf)
[6](http://arxiv.org/pdf/2406.07828.pdf)
[7](https://arxiv.org/html/2410.17839)
[8](https://arxiv.org/html/2501.12637v1)
[9](https://cvpr.thecvf.com/virtual/2023/poster/22127)
[10](https://arxiv.org/html/2507.16406v1)
[11](https://sparsenerf.github.io)
[12](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_SparseNeRF_Distilling_Depth_Ranking_for_Few-shot_Novel_View_Synthesis_ICCV_2023_paper.pdf)
[13](https://pmc.ncbi.nlm.nih.gov/articles/PMC12068573/)
[14](https://arxiv.org/html/2505.06894v1)
[15](http://arxiv.org/pdf/2503.02092.pdf)
[16](https://arxiv.org/html/2506.18208v1)
