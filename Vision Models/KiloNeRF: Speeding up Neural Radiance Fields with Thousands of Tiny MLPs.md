# KiloNeRF: Speeding up Neural Radiance Fields with Thousands of Tiny MLPs

### 1. 핵심 주장과 주요 기여

KiloNeRF의 핵심 주장은 **단일의 대규모 MLP 대신 수천 개의 작은 MLP들을 사용하면 시각 품질을 유지하면서 신경 복사 필드(NeRF)의 렌더링 속도를 획기적으로 향상시킬 수 있다**는 것입니다.[1]

논문의 주요 기여는 다음과 같습니다:[1]

첫째, **분할 정복 전략(divide-and-conquer strategy)**을 통해 3D 씬을 균등한 격자로 분할하고, 각 격자 셀에 독립적인 소형 MLP를 할당합니다. 이렇게 하면 각 MLP는 씬의 일부만 표현하면 되므로 더 작고 빠른 네트워크를 사용할 수 있습니다.

둘째, **교사-학생 증류(teacher-student distillation)** 기반의 3단계 훈련 전략을 제안합니다. 먼저 표준 NeRF를 교사 모델로 훈련하고, KiloNeRF를 학생으로서 교사의 출력과 일치하도록 훈련한 후, 원본 훈련 이미지로 미세조정합니다.

셋째, **공백 공간 건너뛰기(empty space skipping, ESS)** 및 **조기 광선 종료(early ray termination, ERT)**와 같은 최적화 기법을 결합하여 추가적인 성능 향상을 달성합니다.

결과적으로 **원본 NeRF 대비 약 1000배에서 2500배의 렌더링 속도 향상**을 달성했습니다.[1]

---

### 2. 해결하고자 하는 문제와 제안 방법

#### 2.1 문제 정의

NeRF의 가장 큰 병목은 **렌더링 시간**입니다. 원본 NeRF는 한 장의 이미지를 렌더링할 때 수백만 번의 깊고 넓은 MLP 질의가 필요하므로, 현대의 GPU에서도 매우 느립니다. 예를 들어, 800×800 해상도의 이미지를 렌더링하는 데 56초 이상이 소요됩니다.[1]

단순히 네트워크 크기를 줄이면 네트워크 용량 부족으로 인해 복잡한 씬을 정확히 표현할 수 없다는 근본적인 트레이드오프가 존재했습니다.

#### 2.2 핵심 수식

NeRF의 기본 렌더링 공식에서, 각 픽셀에 대해 광선을 따라 K개의 샘플 포인트에서 네트워크를 평가합니다:[1]

$$(c_i, \sigma_i) = f_\theta(x_i, d) \quad \text{for } i = 1, 2, \ldots, K \quad (1)$$

최종 픽셀 색상은 알파 블렌딩으로 계산됩니다:[1]

$$\hat{c} = \sum_{i=1}^{K} T_i \alpha_i c_i \quad (2)$$

여기서:

$$T_i = \prod_{j=1}^{i-1} (1 - \alpha_j) \quad (3)$$

$$\alpha_i = 1 - \exp(-\sigma_i \delta_i) \quad (4)$$

KiloNeRF는 이 과정을 수정하여, 위치 x를 공간 분할(spatial binning)을 통해 해당 MLP 네트워크 인덱스 i로 매핑합니다:[1]

$$g(x) = \left\lfloor \frac{x - b_{\min}}{(b_{\max} - b_{\min})/r} \right\rfloor \quad (6)$$

그리고 해당 네트워크를 쿼리합니다:[1]

$$(c, \sigma) = f_\theta^{(g(x))}(x, d) \quad (7)$$

여기서 $$f_\theta^{(i)}$$는 격자 인덱스 i에 해당하는 작은 MLP입니다.

#### 2.3 모델 아키텍처

KiloNeRF의 MLP는 NeRF의 축소 버전입니다.[1]

**NeRF 아키텍처:**[1]
- 10개의 숨겨진 레이어
- 처음 9개 레이어: 각 256차원 특성 벡터 출력
- 마지막 숨겨진 레이어: 128차원 특성 벡터 출력
- 총 FLOPs: 기준선

**KiloNeRF 아키텍처:**[1]
- 4개의 숨겨진 레이어
- 각 레이어: 32개 숨겨진 유닛
- 총 FLOPs: 원본의 약 1/87
- 스킵 연결 불필요 (네트워크 깊이 감소로 인해)
- 마지막 숨겨진 레이어에 뷰 방향 입력 제공
- RGB 색상 출력에 시그모이드 활성화 함수, 특성 벡터에는 활성화 함수 미적용

#### 2.4 훈련 전략

KiloNeRF는 3단계 훈련 파이프라인을 사용합니다:[1]

**1단계: 교사 NeRF 훈련**
- 표준 NeRF를 600k 반복으로 훈련 (GTX 1080 Ti에서 약 2일 소요)
- 계층적 샘플링 미사용

**2단계: 증류(Distillation)**
- 150k 반복 동안 KiloNeRF 훈련 (약 8시간)
- 학생 네트워크의 밀도(α) 및 색상 값이 교사의 출력과 일치하도록 학습
- 무작위로 샘플된 3D 포인트와 뷰 방향으로 훈련
- L2 손실 함수 사용

**3단계: 미세조정(Fine-tuning)**
- 원본 훈련 이미지로 1000k 반복 훈련 (약 17시간)
- 광도 손실(photometric loss)로 원본 이미지와의 일치 최적화

#### 2.5 정규화 전략

원본 NeRF는 뷰 방향 의존성을 모델링하는 데 전체 용량의 작은 부분만 사용하여, 이것이 빈 공간에서 색상이 뷰 방향의 단순 함수라는 귀납적 편향(inductive bias)을 장려합니다.[1]

KiloNeRF에서는 네트워크 너비 감소로 인해 이 전략을 직접 복제할 수 없으므로, **대신 마지막 두 레이어(뷰 방향 의존 색상 모델링 담당)의 가중치와 편향에 L2 정규화(가중치: 1e-6)를 적용**합니다.[1]

#### 2.6 샘플링 최적화

**공백 공간 건너뛰기(ESS):**[1]
- 더 높은 해상도의 보조 균등 격자 생성 (네트워크 격자 해상도의 16배)
- 각 셀이 씬 콘텐츠를 포함하는지 여부를 나타내는 이진 값으로 채움
- 훈련된 교사 모델에서 추출한 점유도(occupancy) 정보 사용
- 점유된 셀에서만 네트워크 평가

**조기 광선 종료(ERT):**[1]
- 투명도(transmittance) Ti가 임계값 ε = 0.01 이하로 떨어지면 광선 따라 추가 샘플링 중단
- 거리에 따라 네트워크 쿼리를 그룹화하여 구현 (카메라에 가까운 점 먼저 평가)

***

### 3. 성능 향상 결과

#### 3.1 정량적 평가

KiloNeRF는 네 가지 데이터셋에서 평가되었습니다:[1]

| 데이터셋 | 해상도 | 지표 | NeRF | NSVF | KiloNeRF |
|---------|--------|------|------|------|----------|
| BlendedMVS | 768×576 | PSNR ↑ | 27.29 | 26.90 | 27.39 |
| | | SSIM ↑ | 0.91 | 0.90 | 0.92 |
| | | LPIPS ↓ | 0.07 | 0.11 | 0.06 |
| | | 렌더링 시간 ↓ | 37266ms | 4398ms | 30ms |
| Synthetic-NeRF | 800×800 | PSNR ↑ | 31.01 | 31.74 | 31.00 |
| | | SSIM ↑ | 0.95 | 0.95 | 0.95 |
| | | LPIPS ↓ | 0.08 | 0.05 | 0.03 |
| | | 렌더링 시간 ↓ | 56185ms | 4344ms | 26ms |
| Synthetic-NSVF | 800×800 | PSNR ↑ | 31.55 | 35.13 | 33.37 |
| | | SSIM ↑ | 0.95 | 0.98 | 0.97 |
| | | LPIPS ↓ | 0.04 | 0.01 | 0.02 |
| | | 렌더링 시간 ↓ | 56185ms | 10497ms | 26ms |
| Tanks & Temples | 1920×1080 | PSNR ↑ | 28.32 | 28.40 | 28.41 |
| | | SSIM ↑ | 0.90 | 0.90 | 0.91 |
| | | LPIPS ↓ | 0.11 | 0.15 | 0.09 |
| | | 렌더링 시간 ↓ | 182671ms | 15697ms | 91ms |

**핵심 결과:**[1]
- NeRF 대비 **1,258배에서 2,167배의 렌더링 속도 향상**
- NSVF 대비 **약 100배의 속도 향상**
- 시각 품질(PSNR, SSIM)은 기준선과 유사하게 유지
- LPIPS(지각적 품질 지표)에서 대부분의 데이터셋에서 기준선을 능가

#### 3.2 속도 향상 분해

표 2에서 속도 향상이 어디서 오는지 분석합니다:[1]

| 방법 | 렌더링 시간 | NeRF 대비 속도 향상 |
|------|-----------|-----------|
| NeRF (원본) | 56,185 ms | – |
| NeRF + ESS + ERT | 788 ms | 71배 |
| KiloNeRF (전체) | 22 ms | 2,548배 |

이는 **네트워크 크기 축소가 속도 향상의 대부분(약 2,400배 중 2,300배)을 담당**함을 보여줍니다.[1]

***

### 4. 절제 연구(Ablation Study)

논문의 각 구성 요소의 중요성을 검증합니다:[1]

#### 4.1 단일 작은 MLP (Single Tiny MLP)
- 6k 매개변수의 단일 네트워크로 전체 씬 표현 시도
- **결과**: 품질 대폭 저하 (LPIPS: 0.1624)
- **결론**: 공간 분할의 필수성 입증

#### 4.2 반 네트워크 해상도 (Half Network Resolution)
- 격자 해상도를 5×8×5에서 10×16×10로 감소
- **결과**: 품질 저하 (LPIPS: 0.0495 → 0.0809)
- **결론**: 세밀한 격자가 필요함

#### 4.3 반 숨겨진 유닛 (Half #Units)
- 숨겨진 유닛을 32에서 16으로 감소
- **결과**: 품질 약간 저하 (LPIPS: 0.0284 → 0.0340)
- **결론**: 격자 해상도 감소보다 영향 적음

#### 4.4 미세조정 없음 (No Fine-Tuning)
- 증류 단계 후 미세조정 생략
- **결과**: 높은 LPIPS (0.0809)
- **결론**: 미세조정이 품질 향상에 중요함

#### 4.5 증류 없음 (No Distillation)
- 처음부터 직접 훈련
- **결과**: 빈 공간에 뚜렷한 아티팩트 발생
- **결론**: 증류가 아티팩트 제거에 필수적

#### 4.6 가중치 정규화 없음 (No Weight Regularization)
- L2 정규화 제거
- **결과**: 빈 공간에서 시각적 아티팩트 발생
- **결론**: 정규화와 증류 모두 필요함

---

### 5. 한계와 제약 사항

#### 5.1 기술적 한계

**해상도 제약:** KiloNeRF는 중간 해상도 이미지(800×800)를 상호작용 프레임 속도로 렌더링할 수 있지만, 전체 HD(1920×1080) 이미지의 경우 완전한 실시간 렌더링에는 여전히 부족합니다.[1]

**경계 씬 가정:** NSVF와 마찬가지로 KiloNeRF는 축 정렬 경계 상자(AABB)로 정의된 경계 씬을 가정합니다. 야외 씬과 같은 무한 씬을 표현하려면 더 많은 네트워크가 필요하여 메모리 소비가 증가합니다.[1]

**메모리 소비:** 저자들은 네트워크 개수 증가 시 메모리 효율 데이터 구조(예: 희소 복셀 옥트리)를 제안하지만, 현재 방식은 중간 크기 씬에서만 최적입니다.[1]

#### 5.2 일반화 성능의 한계

**씬별 최적화 필요:** KiloNeRF는 각 씬마다 독립적으로 훈련되어야 합니다. 학생 모델은 교사 NeRF에 의존하므로, 교사의 한계를 상속합니다.[1]

**제한된 뷰에서의 성능:** 논문에서 직접 다루지는 않지만, 최신 연구에 따르면 NeRF 기반 방법들은 소수의 입력 뷰에서 과적합과 일반화 문제를 겪습니다.[2][1]

**도메인 일반화 부재:** 훈련된 KiloNeRF는 특정 씬에만 적용되며, 다른 씬에 직접 전이될 수 없습니다.[1]

***

### 6. 모델 일반화 성능 향상 가능성

#### 6.1 논문에서의 일반화 논의

논문은 주로 **주어진 씬 내에서의 렌더링 효율**에 초점을 맞추며, 일반화 능력은 명시적으로 다루지 않습니다. 그러나 몇 가지 인사이트가 있습니다:

**교사-학생 증류의 효과:** 교사 NeRF에서 지식을 추출함으로써, KiloNeRF는 교사의 학습 능력을 어느 정도 상속합니다. 그러나 이는 교사 모델의 일반화 한계에 의해 제한됩니다.[1]

**공간 분할의 이점:** 각 MLP가 특정 공간 영역만 담당하므로 이론적으로는 더 나은 **지역적 특화(local specialization)**를 가능하게 하며, 이는 학습 안정성을 개선할 수 있습니다.[1]

#### 6.2 최신 연구에서의 일반화 성과

2023-2025년 이후의 최신 연구들은 NeRF의 일반화 능력을 크게 향상시켰습니다:[3][4][5][6][7][8]

**일반화 가능한 NeRF 방법들:**[9]
- **NPS (NeRF as Pretraining at Scale)**: 대규모 사전학습을 통해 영역 간 일반화 능력 획기적 향상. 여러 씬에서 학습하여 **제로샷(zero-shot) 및 소수-샷(few-shot) 일반화** 달성.
- **MVSNeRF, IbrNet**: 다중 뷰 입력에서 장면별 특성을 캡처하는 특성 기반 조건화로 교차 씬 일반화 가능.
- **PixelNeRF, MixNeRF**: 사전 학습된 특성과 메타 학습을 활용하여 극도로 제한된 뷰(3-6 뷰)에서도 일반화 가능.

**소수 뷰 시나리오에서의 개선:**[10][11][2]
- **TVNeRF**: 스파스 입력에서 총변동(Total Variation) 정규화를 사용하여 과적합 완화.
- **FreeNeRF, AR-NeRF**: 주파수 정규화를 통해 기하학적 일관성 개선.
- **SPARF**: 특성 기반 제약으로 정규화 효율 향상.

#### 6.3 KiloNeRF 기반의 일반화 향상 가능성

KiloNeRF의 아키텍처는 다음 방식으로 일반화 개선에 기여할 수 있습니다:

**1. 공간적 구조화된 학습:**[1]
- 각 MLP가 로컬 영역만 담당하므로, 더 단순한 함수를 학습해야 합니다.
- 이는 이론적으로 **과적합 위험을 감소**시킬 수 있습니다.

**2. 효율적인 교사-학생 증류 확장:**
- 최신 연구에서 제안한 다단계 파이프라인(MuSt-NeRF)처럼, 깊이-유도 및 광도-정제 단계를 적용하면 로컬 MLP들의 기하학적 일관성 개선 가능.[12]

**3. 사전 학습 통합:**
- KiloNeRF의 로컬 MLP 구조에 **DINO, DINOv2 같은 사전 학습 특성**을 조건으로 추가하면, 일반화 가능한 NeRF로 변환 가능.
- 다만, 최근 연구는 극도의 소수-샷(5 뷰) 시나리오에서 사전 학습 특성이 항상 도움이 되는 것은 아님을 보여줍니다.[13]

**4. 메타 학습 적용:**[5]
- FewShotNeRF처럼 메타 학습을 통해 로컬 MLP들의 초기화를 최적화하면, 새로운 씬에 대한 빠른 적응 가능.

***

### 7. 후속 연구에 미치는 영향 및 고려 사항

#### 7.1 학계에 미친 영향

**렌더링 효율의 새로운 벤치마크:**[14][15]
KiloNeRF는 NeRF 가속화 연구에 중요한 이정표를 제시했습니다. 이후 FastNeRF, PlenOctree, Plenoxels 같은 방법들이 등장했으며, 최근의 3D Gaussian Splatting은 KiloNeRF보다 훨씬 빠른 렌더링(100+ FPS)을 달성하고 있습니다.[16]

**공간 분할 전략의 보편화:**[1]
KiloNeRF 이후 많은 연구에서 **공간 분해(spatial decomposition)** 아이디어를 채택했습니다. 예를 들어, AutoInt는 수치 적분을 제거했고, DONeRF는 샘플 배치를 최적화했습니다.[17][9]

**증류 기반 최적화 전략:**[18][12][1]
교사-학생 증류 파이프라인은 이후 여러 NeRF 변형에 채택되어, 특히 **MuSt-NeRF**, **GP-NeRF**, **GHNeRF** 같은 최신 방법들에서 핵심 기법으로 활용됩니다.[19][12]

#### 7.2 현재 기술 동향과의 비교

**3D Gaussian Splatting의 등장 (2023):**[16]
- **성능**: 100+ FPS 렌더링 (KiloNeRF의 ~3-4배 빠름)
- **메모리**: 더 많은 메모리 소비 (수백 MB)
- **교점**: KiloNeRF의 공간 분해 개념이 3DGS 최적화(예: Speedy-Splat, AdR-Gaussian)에 영감을 제공[20][21]

**Instant-NGP 및 해시 그리드 방식:**[22][23]
- 다중 레벨 해시 그리드로 특성 인코딩 → 매우 빠른 렌더링 가능
- 메모리 효율성은 KiloNeRF보다 나음
- 최근 개선: **NeRFLight**는 Instant-NGP를 능가하는 FPS/MB 달성[23]

**일반화 가능한 NeRF의 발전:**
- KiloNeRF는 씬별 최적화 방식이지만, 최신 연구들은 **교차 씬 일반화**에 집중[4][6][7][3][5][9]
- 일반화와 효율성의 결합이 새로운 연구 방향

#### 7.3 향후 연구 시 고려할 점

**1. 경계 없는 씬에 대한 확장:**[11][1]
- KiloNeRF는 경계 씬을 가정하는데, Mip-NeRF 360이나 p-norm 기반 매핑 같은 기법을 통합하면 야외 씬 처리 가능.[11]
- 이를 통해 저장소 이슈 해결 가능.

**2. 적응적 격자 해상도:**
- 현재 고정 격자 해상도 대신, **기하학적 복잡도에 따라 동적으로 격자 해상도 조정** → 메모리 효율성 및 시각 품질 동시 개선.

**3. 일반화 능력 통합:**
- KiloNeRF의 공간 분해와 최신 일반화 기법(사전 학습 특성, 메타 학습)의 결합으로 **제로-샷 또는 소수-샷 일반화 가능한 고속 렌더링 방법** 개발.

**4. 모바일 및 엣지 디바이스 배포:**
- 소형 모델(KiloNeRF)의 장점을 극대화하여 **제한된 메모리/전력 환경에서도 실시간 렌더링** 달성.
- 이는 AR/VR 애플리케이션의 실용화에 필수.

**5. 동적 씬 확장:**
- 현재 정적 씬만 지원하는데, **비디오 기반 NeRF나 동적 NeRF**와 KiloNeRF 결합 시 초당 프레임 향상 가능.

**6. 비교 기준(Baseline) 갱신:**
- 최신 방법들(3DGS, Instant-NGP, Mip-NeRF 360)과의 정량적 비교를 통해 KiloNeRF의 현재 위치 재평가 필요.
- 일반화 능력, 메모리 효율, 훈련 속도 등 다각적 평가 필요.

**7. 하이브리드 접근:**
- KiloNeRF와 3DGS, 또는 KiloNeRF와 해시 그리드 기반 방법의 결합으로 시너지 창출 가능.

***

### 결론

KiloNeRF는 **신경 복사 필드의 렌더링 효율 문제를 근본적으로 해결하는 영향력 있는 논문**입니다. 단순하면서도 효과적인 공간 분해 전략과 교사-학생 증류 기법을 통해 1000배 이상의 속도 향상을 달성했습니다.[1]

그러나 **경계 씬 가정, 씬별 최적화 필요, 교차-씬 일반화 부재** 같은 한계도 명확합니다. 최신 연구들은 이러한 한계를 극복하기 위해 **일반화 능력 강화, 무한 씬 지원, 적응적 구조** 등에 집중하고 있습니다.[6][7][8][3][4][5][12][1]

KiloNeRF 이후 3D Gaussian Splatting 같은 경쟁 기술이 등장했지만, **KiloNeRF의 공간 분해 개념과 증류 전략은 여전히 현대 NeRF 변형과 최적화 방법들의 기초를 이루고 있습니다.** 앞으로의 연구는 렌더링 효율과 일반화 능력의 균형을 맞추면서, 실제 애플리케이션(AR/VR, 로봇 비전 등)에 대한 실용성을 강화하는 방향으로 진화할 것으로 예상됩니다.[21][20]

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/4a490e17-1d17-45d5-8fa3-c7bc47cfdb95/2103.13744v2.pdf)
[2](https://www.sciencedirect.com/science/article/abs/pii/S0950705124009079)
[3](https://arxiv.org/html/2402.01217v3)
[4](https://arxiv.org/html/2410.12242v1)
[5](https://arxiv.org/html/2408.04803v1)
[6](https://arxiv.org/pdf/2403.03608.pdf)
[7](http://arxiv.org/pdf/2404.06246.pdf)
[8](http://arxiv.org/pdf/2304.11842.pdf)
[9](https://openaccess.thecvf.com/content/CVPR2024W/NRI/papers/Cong_NeRF_as_Pretraining_at_Scale_Generalizable_3D-Aware_Semantic_Representation_Learning_CVPRW_2024_paper.pdf)
[10](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/08292.pdf)
[11](https://proceedings.iclr.cc/paper_files/paper/2024/file/3b62aa13a97d50ab75e6763750093386-Paper-Conference.pdf)
[12](https://arxiv.org/html/2311.11863v2)
[13](https://arxiv.org/html/2506.18208v1)
[14](https://openaccess.thecvf.com/content/ICCV2021/papers/Reiser_KiloNeRF_Speeding_Up_Neural_Radiance_Fields_With_Thousands_of_Tiny_ICCV_2021_paper.pdf)
[15](http://www.txxb.com.cn/EN/abstract/abstract2220.shtml)
[16](https://xoft.tistory.com/51)
[17](http://arxiv.org/pdf/2502.14938.pdf)
[18](https://www.scitepress.org/Papers/2025/131691/131691.pdf)
[19](https://openaccess.thecvf.com/content/CVPR2024/papers/Li_GP-NeRF_Generalized_Perception_NeRF_for_Context-Aware_3D_Scene_Understanding_CVPR_2024_paper.pdf)
[20](https://openaccess.thecvf.com/content/CVPR2025/papers/Hanson_Speedy-Splat_Fast_3D_Gaussian_Splatting_with_Sparse_Pixels_and_Sparse_CVPR_2025_paper.pdf)
[21](https://arxiv.org/html/2409.08669v1)
[22](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136770258.pdf)
[23](https://openaccess.thecvf.com/content/CVPR2023/papers/Rivas-Manzaneque_NeRFLight_Fast_and_Light_Neural_Radiance_Fields_Using_a_Shared_CVPR_2023_paper.pdf)
